{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":25947,"status":"ok","timestamp":1727345625407,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"},"user_tz":-330},"id":"rk1w-6o6qzQX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3a6f87d-7f61-4482-96aa-b99e5ade6d2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.5/602.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for durationpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1104,"status":"ok","timestamp":1727504376431,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"},"user_tz":-330},"id":"3weJ8yBLrXFs"},"outputs":[],"source":["from IPython.display import display, Markdown\n","import textwrap\n","import google.generativeai as genai\n","\n","# Function to convert text to markdown\n","def to_markdown(text):\n","    text = text.replace('•', '  *')\n","    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n","\n","\n","GOOGLE_API_KEY = \"AIzaSyCYpd2K12aKETeIPiBnbB6Iiwaqa1ZYQXk\"\n","\n","\n","genai.configure(api_key=GOOGLE_API_KEY)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":561,"status":"ok","timestamp":1727504395601,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"},"user_tz":-330},"id":"-tdLUpbnBmpQ","outputId":"4077686f-e774-4a9d-bcd8-9256e7aad274"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["genai.GenerativeModel(\n","    model_name='models/gemini-1.5-flash',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n","    cached_content=None\n",")"]},"metadata":{},"execution_count":4}],"source":["\n","model = genai.GenerativeModel(model_name = \"gemini-1.5-flash\")\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQ7dZTemBtcP"},"outputs":[],"source":["response = model.generate_content(\"What are the usecases of LLMs?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":777},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1727345632807,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"},"user_tz":-330},"id":"_PH0HfJBBwi_","outputId":"492d9d2c-6110-4cf0-9b40-05f70a4d8903"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> Large Language Models (LLMs) are incredibly versatile tools with a wide range of potential use cases across many industries. Here are some of the most prominent:\n> \n> **Content Creation:**\n> \n> * **Writing:** Generating articles, blog posts, social media content, scripts, poems, code, emails, and more.\n> * **Translation:** Translating text between languages with high accuracy.\n> * **Summarization:** Condensing large amounts of text into concise summaries.\n> * **Dialogue Generation:** Creating realistic and engaging chatbots for customer service, education, and entertainment.\n> \n> **Information Retrieval & Analysis:**\n> \n> * **Search:** Enhancing search engines with more natural language understanding and providing more relevant results.\n> * **Data Analysis:** Extracting insights and patterns from large datasets by analyzing text, code, or other data.\n> * **Fact Checking:** Identifying and verifying information for accuracy and bias.\n> * **Question Answering:** Answering user queries in a comprehensive and informative way.\n> \n> **Education & Research:**\n> \n> * **Personalized Learning:** Tailoring educational content to individual student needs and learning styles.\n> * **Research Assistance:** Automating research tasks like literature review, data analysis, and hypothesis generation.\n> * **Language Learning:** Providing interactive and personalized language learning experiences.\n> \n> **Business & Industry:**\n> \n> * **Customer Service:** Automating customer interactions, providing personalized support, and resolving issues quickly.\n> * **Marketing & Sales:** Generating personalized marketing copy, creating targeted campaigns, and automating customer interactions.\n> * **Legal & Finance:** Analyzing legal documents, summarizing financial reports, and automating tasks like contract review.\n> * **Healthcare:** Assisting with medical diagnosis, drug discovery, and patient care by analyzing medical records and literature.\n> \n> **Creative & Entertainment:**\n> \n> * **Storytelling:** Generating creative stories, poems, and scripts.\n> * **Music Composition:** Creating original music pieces and generating variations on existing themes.\n> * **Art Generation:** Generating images and videos based on text prompts.\n> \n> **Other Use Cases:**\n> \n> * **Accessibility:** Creating tools for people with disabilities, such as text-to-speech or speech-to-text.\n> * **Code Generation:** Automating code writing and debugging tasks.\n> * **Robotics & Automation:** Enabling robots to interact with humans more naturally.\n> * **Social Good:** Addressing social issues like misinformation, discrimination, and poverty.\n> \n> **It's important to note that LLMs are still under development and have limitations:**\n> \n> * **Bias and Fairness:** LLMs can reflect and amplify biases present in their training data.\n> * **Lack of Common Sense:** LLMs may struggle with understanding nuanced situations and making common sense judgments.\n> * **Factual Errors:** LLMs can generate inaccurate or fabricated information, especially when dealing with unfamiliar topics.\n> * **Ethical Concerns:** There are concerns about the potential misuse of LLMs for malicious purposes, such as creating fake news or deepfakes.\n> \n> Despite these limitations, LLMs have the potential to revolutionize many aspects of our lives. As the technology continues to develop, we can expect to see even more innovative and impactful use cases emerge.\n"},"metadata":{},"execution_count":5}],"source":["to_markdown(response.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4tphLHgB12A"},"outputs":[],"source":["from langchain_google_genai import ChatGoogleGenerativeAI\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HwWrVaEoB__9"},"outputs":[],"source":["\n","# Store the Google API key as a string\n","GOOGLE_API_KEY = \"AIzaSyCYpd2K12aKETeIPiBnbB6Iiwaqa1ZYQXk\"\n","\n","# Initialize the ChatGoogleGenerativeAI with the API key\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rosxy6G2Cbvp"},"outputs":[],"source":["result = llm.invoke(\"What are the usecases of LLMs?\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6wc-BonCe2w","colab":{"base_uri":"https://localhost:8080/","height":620},"executionInfo":{"status":"ok","timestamp":1727345641164,"user_tz":-330,"elapsed":30,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"outputId":"150625c3-d2fe-4831-c91f-34d53852ff59"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> **Natural Language Processing (NLP):**\n> \n> * **Language Translation:** Translating text from one language to another\n> * **Text Summarization:** Condensing large amounts of text into shorter, informative summaries\n> * **Question Answering:** Providing answers to questions based on provided text\n> * **Chatbots:** Creating virtual assistants and customer service agents that can communicate in natural language\n> * **Sentiment Analysis:** Identifying and classifying the emotional tone of text\n> \n> **Creative Content Generation:**\n> \n> * **Story Writing:** Generating original stories, poems, and other creative content\n> * **Songwriting:** Creating lyrics and melodies for songs\n> * **Code Generation:** Generating code in various programming languages\n> * **Image Captioning:** Describing images in written form\n> * **Dialogue Writing:** Creating realistic and engaging dialogue for screenplays, plays, or video games\n> \n> **Business Applications:**\n> \n> * **Customer Service Automation:** Handling inquiries and resolving issues through chatbots\n> * **Content Marketing:** Creating high-quality, SEO-optimized content\n> * **Market Research:** Analyzing consumer feedback and market trends\n> * **Risk Assessment:** Identifying potential risks and vulnerabilities in text data\n> * **Legal Document Review:** Reviewing and summarizing legal documents\n> \n> **Education:**\n> \n> * **Personalized Learning:** Providing tailored learning materials and assessments based on individual student needs\n> * **Language Learning:** Assisting students with language acquisition and practice\n> * **Historical Research:** Analyzing historical texts and extracting key insights\n> * **Essay Grading:** Evaluating student essays and providing feedback\n> * **Scientific Paper Summarization:** Condensing complex scientific papers into accessible summaries\n> \n> **Other Use Cases:**\n> \n> * **Healthcare:** Assisted diagnosis, drug discovery, and patient communication\n> * **Finance:** Financial analysis, risk modeling, and fraud detection\n> * **Social Media:** Content moderation, trend analysis, and community management\n> * **Gaming:** Creating interactive dialogues, storylines, and game mechanics\n> * **Virtual Reality:** Generating realistic virtual environments and experiences"},"metadata":{},"execution_count":9}],"source":["\n","to_markdown(result.content)"]},{"cell_type":"markdown","metadata":{"id":"KP_a1ZepfOAu"},"source":["# **Retreival Augment Generation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-J7X9TNBCkuw","executionInfo":{"status":"ok","timestamp":1727345671435,"user_tz":-330,"elapsed":30296,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"outputId":"d6526212-68b3-48a1-d0b3-1dee77396ad3","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["The following additional packages will be installed:\n","  libarchive-dev libleptonica-dev tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr\n","  tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 6 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 8,560 kB of archives.\n","After this operation, 31.6 MB of additional disk space will be used.\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libarchive-dev:amd64.\n","(Reading database ... 123605 files and directories currently installed.)\n","Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n","Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n","Selecting previously unselected package libleptonica-dev.\n","Preparing to unpack .../1-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n","Unpacking libleptonica-dev (1.82.0-3build1) ...\n","Selecting previously unselected package libtesseract-dev:amd64.\n","Preparing to unpack .../2-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n","Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Selecting previously unselected package tesseract-ocr-eng.\n","Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../5-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up libleptonica-dev (1.82.0-3build1) ...\n","Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 29.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 123785 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../01-poppler-data_0.4.11-1_all.deb ...\n","Unpacking poppler-data (0.4.11-1) ...\n","Selecting previously unselected package antiword.\n","Preparing to unpack .../02-antiword_0.37-16_amd64.deb ...\n","Unpacking antiword (0.37-16) ...\n","Selecting previously unselected package flac.\n","Preparing to unpack .../03-flac_1.3.3-2ubuntu0.2_amd64.deb ...\n","Unpacking flac (1.3.3-2ubuntu0.2) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../04-fonts-noto-mono_20201225-1build1_all.deb ...\n","Unpacking fonts-noto-mono (20201225-1build1) ...\n","Selecting previously unselected package fonts-urw-base35.\n","Preparing to unpack .../05-fonts-urw-base35_20200910-1_all.deb ...\n","Unpacking fonts-urw-base35 (20200910-1) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../06-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n","Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n","Selecting previously unselected package libidn12:amd64.\n","Preparing to unpack .../07-libidn12_1.38-4ubuntu1_amd64.deb ...\n","Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../08-libijs-0.35_0.35-15build2_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../09-libjbig2dec0_0.19-3build2_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../10-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n","Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n","Selecting previously unselected package ghostscript.\n","Preparing to unpack .../11-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n","Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n","Selecting previously unselected package lame.\n","Preparing to unpack .../12-lame_3.100-3build2_amd64.deb ...\n","Unpacking lame (3.100-3build2) ...\n","Selecting previously unselected package libid3tag0:amd64.\n","Preparing to unpack .../13-libid3tag0_0.15.1b-14_amd64.deb ...\n","Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n","Selecting previously unselected package libmad0:amd64.\n","Preparing to unpack .../14-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n","Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n","Selecting previously unselected package libopencore-amrnb0:amd64.\n","Preparing to unpack .../15-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libopencore-amrwb0:amd64.\n","Preparing to unpack .../16-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libsox3:amd64.\n","Preparing to unpack .../17-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libsox-fmt-alsa:amd64.\n","Preparing to unpack .../18-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libwavpack1:amd64.\n","Preparing to unpack .../19-libwavpack1_5.4.0-1build2_amd64.deb ...\n","Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n","Selecting previously unselected package libsox-fmt-base:amd64.\n","Preparing to unpack .../20-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libsox-fmt-mp3:amd64.\n","Preparing to unpack .../21-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libxslt1-dev:amd64.\n","Preparing to unpack .../22-libxslt1-dev_1.1.34-4ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n","Selecting previously unselected package poppler-utils.\n","Preparing to unpack .../23-poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n","Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n","Selecting previously unselected package pstotext.\n","Preparing to unpack .../24-pstotext_1.9-6build1_amd64.deb ...\n","Unpacking pstotext (1.9-6build1) ...\n","Selecting previously unselected package sox.\n","Preparing to unpack .../25-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package swig4.0.\n","Preparing to unpack .../26-swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n","Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../27-swig_4.0.2-1ubuntu1_all.deb ...\n","Unpacking swig (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package unrtf.\n","Preparing to unpack .../28-unrtf_0.21.10-clean-1_amd64.deb ...\n","Unpacking unrtf (0.21.10-clean-1) ...\n","Setting up unrtf (0.21.10-clean-1) ...\n","Setting up libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n","Setting up fonts-noto-mono (20201225-1build1) ...\n","Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libijs-0.35:amd64 (0.35-15build2) ...\n","Setting up fonts-urw-base35 (20200910-1) ...\n","Setting up lame (3.100-3build2) ...\n","Setting up poppler-data (0.4.11-1) ...\n","Setting up libid3tag0:amd64 (0.15.1b-14) ...\n","Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Setting up flac (1.3.3-2ubuntu0.2) ...\n","Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n","Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n","Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n","Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n","Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Setting up antiword (0.37-16) ...\n","Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n","Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n","Setting up swig4.0 (4.0.2-1ubuntu1) ...\n","Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n","Setting up swig (4.0.2-1ubuntu1) ...\n","Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n","Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n","Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up pstotext (1.9-6build1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Collecting langchain\n","  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.6)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.128)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Installing collected packages: langchain-text-splitters, langchain\n","Successfully installed langchain-0.3.1 langchain-text-splitters-0.3.0\n"]}],"source":["!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n","\n","!sudo apt-get -y -qq install poppler-utils libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n","\n","!pip install langchain\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5qnM1ttghs3","executionInfo":{"status":"ok","timestamp":1727345676673,"user_tz":-330,"elapsed":5259,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"outputId":"21d6e118-b54b-43a5-95d0-2175ffbe1e20","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.1)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.6)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.128)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"]}],"source":["!pip install -U langchain-community"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5M_xUYxfXTa"},"outputs":[],"source":["import urllib\n","import warnings\n","from pathlib import Path as p\n","from pprint import pprint\n","\n","import pandas as pd\n","from langchain import PromptTemplate\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","\n","\n","\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHz9uj9Kfe7q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2U7CSBEf0sX"},"outputs":[],"source":["#setting up the model\n","\n","model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY,\n","                             temperature=0.2,convert_system_message_to_human=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vp98hC47f3os","executionInfo":{"status":"ok","timestamp":1727345959596,"user_tz":-330,"elapsed":30775,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"outputId":"69d0c605-2d43-4966-fbcd-a35bb47f6bf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["This is an electronic version of the print te xtbook. Due to electronic rights restrictions, \n","some third party content may be  suppressed. Editorial review has deemed that any suppressed \n","content does not materially affect the overall lear ning experience. The publisher reserves the right \n","to remove content from this title at any time if subsequent rights restrictions require it. For \n","valuable information on pricing, previous editio ns, changes to current editions, and alternate \n","formats, please visit www.cengage.com/highered to search by ISBN#, author, title, or keyword for \n","materials in your areas of interest. \n","      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \n","Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\n"]}],"source":["#loading the pdf\n","pdf_loader = PyPDFLoader(\"/content/Mathematical_Statistics_with_Application_-_7th_edition[1].pdf\")\n","pages = pdf_loader.load_and_split()\n","print(pages[3].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_3yE4RJf__1","executionInfo":{"status":"ok","timestamp":1727345979079,"user_tz":-330,"elapsed":645,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dba99285-f7b5-4455-8300-a272d7d323ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["981"]},"metadata":{},"execution_count":39}],"source":["len(pages)"]},{"cell_type":"markdown","metadata":{"id":"lTtOc5Yngv63"},"source":["# **RAG Pipeline: Embedding and Gemini (LLM)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auB8jTyogsjl"},"outputs":[],"source":["\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HemVwh1g1xA"},"outputs":[],"source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n","context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n","texts = text_splitter.split_text(context)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"St3DjIqrg4R0"},"outputs":[],"source":["\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFEfIDL8g7H9"},"outputs":[],"source":["vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKVHYj1mhAd9"},"outputs":[],"source":["qa_chain = RetrievalQA.from_chain_type(\n","    model,\n","    retriever=vector_index,\n","    return_source_documents=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFvbC0EzhC5h","executionInfo":{"status":"ok","timestamp":1727346032181,"user_tz":-330,"elapsed":1460,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9886720d-779a-4362-e7fa-067d0e4e4ebd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm sorry, but the provided text does not contain information about the Multi-head attention layer. \\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}],"source":["question = \"Describe the Multi-head attention layer in detail?\"\n","result = qa_chain({\"query\": question})\n","result[\"result\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WO-uFzRChIHw","executionInfo":{"status":"ok","timestamp":1727346032182,"user_tz":-330,"elapsed":12,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f900312d-ec1a-4ee4-8ad1-fe8e080a2cfd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"I'm sorry, but the provided text does not contain information about the Multi-head attention layer. \n"},"metadata":{},"execution_count":46}],"source":["Markdown(result[\"result\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"u9jN-jJihPjV","executionInfo":{"status":"ok","timestamp":1727346032182,"user_tz":-330,"elapsed":11,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a59b801d-2e25-4e25-c71a-52feaefc1373"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={}, page_content='12.4 Some Elementary Experimental Designs 651\\n12.17 Refer to the matched-pairs e xperiment and assume that the ith measurement (i=1,2),i nt h e\\njth pair, where j=1,2,...,n ,i s\\nYij=μi+Uj+εij,\\nwhere μi=expected response for population i,w h e r e i=1,2,\\nUj=ar a n d o mv a r i a b l et h a ti su n i f o r m l ydistributed on the interval (−1,+1),\\nεij=random error associated with the ith measurement in the jth pair.\\nAssume that the εij’s are independent normal random variables with E(εij)=0and\\nV(εij)=σ2,a n dt h a t Ujandεijare independent.\\naFind E(Yij).\\nbArgue that the Y1j’s, for j=1,2,...,n ,a r enot normallydistributed. (There is no need\\nto actuallyﬁnd the distribution of the Y1-values.)\\ncShow that Cov( Y1j,Y2j)=1/3, for j=1,2,...,n .\\ndShow that Dj=Y1j−Y2jare independent, normall ydistributed random variables.\\neIn parts (a)–(d), you veriﬁed that the differences within each pair can be normallydistributed\\neven though the individual measurements within the pairs are not. Can you come up with\\nanother e xample that illustrates this same phenomenon?\\n12.4 Some Elementary Experimental Designs\\nIn Chapters 8 and 10,w ec o n s i d e r e dm e t h o d st oc o m p a r et h em e a n so ft w op o p -\\nulations based on independent random samples obtained from each. Section 12.3\\ndealt with a comparison of two population means through the matched-pairs e xper-\\niment. In this section, we present general considerations associated with designing\\nexperiments. Speciﬁcally,w ec o n s i d e re xtensions of the independent samples and\\nmatched-pairs methodologies when the objective is to compare the means of more\\nthan two populations.\\nSuppose that we wish to compare ﬁve teaching techniques, A, B, C, D, and E, and\\nthat we use 125 students in the stud y.T h eo b j e c t i v ei st oc o m p a r et h em e a ns c o r e s\\non a standardized test for students taught byeach of the ﬁve methods. How would\\nwe proceed? Even though the 125 students are in some sense representative of the\\nstudents that these teaching methods target, are the students all identical? The answer\\nis obviouslyno.\\nThere are likelyto be bo ysa n dg i r l si nt h eg r o u p ,a n dt h em e t h o d sm i g h tn o tb e\\nequallyeffective for both genders. There are likel yto be differences in the native\\nabilities of the students in the group, resulting in some students performing better\\nregardless of the teaching method used. Different students maycome from families\\nthat place different emphases on education, and this could have an impact on the\\nscores on the standardized test. In addition, there maybe other differences among the\\n125 students that would have an unanticipated effect on the test scores.\\nBased on these considerations, we decide that it might be wise to randomly as-\\nsign 25 students to each of ﬁve groups. Each group will be taught using one of the\\ntechniques under study.T h er a n d o md i v i s i o no ft h es t u d e n t si n t ot h eﬁ v eg r o u p s\\nachieves two objectives. First, we eliminate the possible biasing effect of individual\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n652 Chapter 12 Considerations in Designing Experiments\\ncharacteristics of the students on the measurements that we make. Second, it provides\\nap r o b a b i l i s t i cb a s i sf o rt h es e l e c t i o no ft h es a m p l et h a tp e r m i t st h es t a t i s t i c i a nt o\\ncalculate probabilities associated with the observations in the sample and to use these\\nprobabilities in making inferences.\\nThe preceding e xperiment illustrates the basic components of a designed e xperi-\\nment. The e xperimental units in this studyare the individual students.\\nDEFINITION 12.1 Experimental units are the objects upon which measurements are taken.\\nThis e xperiment involves a single factor—namely,m e t h o do ft e a c h i n g .I nt h i s\\nexperiment, the factor has ﬁve levels:A ,B ,C ,D ,a n dE .\\nDEFINITION 12.2 Factors are variables completelycontrolled bythe e xperimenter. The intensit y\\nlevel (distinct subcategory)o faf a c t o ri sc a l l e di t slevel.\\nIn a single-factor e xperiment like the preceding one, each level of the single factor\\nrepresents a treatment.T h u s ,i no u re d u c a t i o ne xample, there are ﬁve treatments,\\none corresponding to each of the teaching methods. As another e xample, consider\\nan experiment conducted to investigate the effect of various amounts of nitrogen and\\nphosphate on the yield of a varietyof corn. An experimental unit would be a speciﬁed\\nacreage—say,1a c r e — o fc o r n .Atreatment would be a ﬁ xed number of pounds of\\nnitrogen x1and of phosphate x2applied to a given acre of corn. For e xample, one\\ntreatment might be to use x1=100pounds of nitrogen per acre and x2=200pounds\\nof phosphate. A second treatment might correspond to x1=150and x2=100.N o t i c e\\nthat the e xperimenter could use different amounts (x1,x2)of nitrogen and phosphate\\nand that each combination would represent a different treatment.\\nDEFINITION 12.3 Atreatment is a speciﬁc combination of factor levels.\\nThe preceding e xperiment for comparing teaching methods A, B, C, D, and E\\nentailed randomly dividing the 125 students into ﬁve groups, each of si ze2 5 .E a c h\\ngroup received e xactlyone of the treatments. This is an e xample of a completely\\nrandomized design.\\nDEFINITION 12.4 Acompletely randomized design to compare ktreatments is one in which a\\ngroup of nrelativelyhomogeneous e xperimental units are randomlydivided\\ninto ksubgroups of sizes n1,n2,...,n k(where n1+n2+···+n k=n).\\nAll e xperimental units in each subgroup receive the same treatment, with each\\ntreatment applied to e xactlyone subgroup.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.'),\n"," Document(metadata={}, page_content='13.5 A Statistical Model for the One-Way Layout 677\\n13.14 The Florida Game and Fish Commission desires to compare the amounts of residue from\\nthree chemicals found in the brain tissue of brown pelicans. Independent random samples\\nof ten pelicans each yielded the accompan ying results (measurements in parts per million). Is\\nthere evidence of sufﬁcient differences among the mean residue amounts, at the 5% level of\\nsigniﬁcance?\\nChemical\\nStatistic DDE DDD DDT\\nMean .032 .022 .041\\nStandard deviation .014 .008. 017\\n13.15 Water samples were taken at four different locations in a river to determine whether the quantit y\\nof dissolved o xygen, a measure of water pollution, differed from one location to another.\\nLocations 1 and 2 were selected above an industrial plant, one near the shore and the other in\\nmidstream; location 3 was adjacent to the industrial water discharge for the plant; and location\\n4w a ss l i g h t l ydownriver in midstream. Five water specimens were randomlyselected at each\\nlocation, but one specimen, from location 4, was lost in the laboratory.T h ed a t aa r es h o w n\\nin the accompan ying table (the greater the pollution, the lower will be the dissolved oxygen\\nreadings). Do the data provide sufﬁcient evidence to indicate a difference in mean dissolved\\noxygen content for the four locations? Give bounds for the attained signiﬁcance level.\\nLocation Dissolved Oxygen Content\\n15 . 9 6 . 1 6 . 3 6 . 1 6 . 0\\n26 . 3 6 . 6 6 . 4 6 . 4 6 . 5\\n34 . 8 4 . 3 5 . 04.7 5.1\\n46 . 06.2 6.1 5.8\\n13.16 An e xperiment was conducted to e xamine the effect of age on heart rate when subjects perform\\nas p e c i ﬁ ca m o u n to fe xercise. Ten male subjects were randomlyselected from four age groups:\\n10–19, 20–39, 40–59, and 60–69. Each subject walked a treadmill at a ﬁxed grade for a period\\nof 12 minutes, and the increase in heart rate—the difference in rates before and after e xercise—\\nwas recorded (in beats per minute). Preliminar ycalculations yielded Total SS =1002.975 and\\nSST=67.475.\\naConstruct the associated ANOV A table.\\nbDo the data provide sufﬁcient evidence to indicate differences in mean increase in heart\\nrate among the four age groups? Test b yusing α=.05.\\n13.5 AS t a t i s t i c a lM o d e lf o rt h eO n e - W a yL a y o u t\\nAs earlier, we let Yijdenote the random variables that generate the observed values yij,\\nfori=1,2,...,k andj=1,2,...,n i.T h e Yij-values correspond to independent\\nrandom samples from normal populations with E(Yij)=μiandV(Yij)=σ2,f o r\\ni=1,2,...,k andj=1,2,...,n i.L e tu sc o n s i d e rt h er a n d o ms a m p l ed r a w nf r o m\\npopulation 1 and write\\nY1j=μ1+ε1j, j=1,2,...,n 1.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n678 Chapter 13 The Analysis of Variance\\nEquivalently,\\nε1j=Y1j−μ1, j=1,2,...,n 1.\\nBecause ε1jis the difference between a normallydistributed random variable and\\nits mean, it follows that ε1jis normallydistributed with E(ε1j)=0and V(ε1j)=\\nV(Y1j)=σ2.F u r t h e r ,t h ei n d e p e n d e n c eo f Y1j,f o r j=1,2,...,n 1,i m p l i e st h a t\\nε1j,f o r j=1,2,...,n 1,a r em u t u a l l yindependent random variables. For each\\ni=1,2,...,k ,w ec a np r o c e e di na na n a l o g o u sm a n n e rt ow r i t e\\nYij=μi+εij, j=1,2,...,n i,\\nwhere the “error terms” εijare independent, normallydistributed random variables\\nwith E(εij)=0and V(εij)=σ2,f o r i=1,2,...,k and j=1,2,...,n i.T h e\\nerror terms simplyrepresent the difference between the observations in each sample\\nand the corresponding population means.\\nOne more set of considerations will lead to the classical model for the one-way\\nlayout. Consider the means μi,f o ri=1,2,...,k ,a n dw r i t e\\nμi=μ+τi where τ1+τ2+···+τ k=0.\\nNotice that∑k\\ni=1μi=kμ+∑k\\ni=1τi=kμ,a n dh e n c eμ =k−1∑k\\ni=1μiis just\\nthe average of the kpopulation means (the μi-values). For this reason, μis generally\\nreferred to as the overall mean .S i n c ef o r i=1,2,...,k ,τi=μi−μquantiﬁes\\nthe difference between the mean for population iand the overall mean, τiis usually\\nreferred to as the effect of treatment (or population) i.F i n a l l y,w ep r e s e n tt h ec l a s s i c a l\\nmodel for the one-waylayout.\\nStatistical Model for a One-Way Layout\\nFori=1,2,...,k andj=1,2,...,n i,\\nYij=μ+τi+εij\\nwhere Yij=thejth observation from population (treatment) i,\\nμ=the overall mean,\\nτi=the nonrandom effect of treatment i,w h e r e∑k\\ni=1τi=0,\\nεij=random error terms such that εijare independent normally\\ndistributed random variables with E(εij)=0and V(εij)=σ2.\\nThe advantage of this model is that it veryclearlysummarizes all the assumptions\\nmade in the analysis of the data obtained from a one-waylayout. It also gives us a\\nbasis for presenting a precise statistical model for the randomized block design. (See\\nSection 13.8.)\\nNotice that (see Exercise 13.19) H0:μ1=μ2=···=μ kcan be restated as\\nH0:τ1=τ2=···=τ k=0\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n13.6 Proof of Additivity of the Sums of Squares and E(MST) for a One-Way Layout (Optional) 679\\nand that Ha:μi̸=μi′for some i̸=i′is equivalent to Ha:τi̸=0for some i,\\n1≤i≤k.T h u s ,t h e Ftest for equalityof means that we presented in Section 13.3\\nis the test of the hypotheses\\nH0:τ1=τ2=···=τ k=0versus Ha:τi̸=0for some i,1≤i≤k.\\nExercises\\n13.17 LetYi•denote the average of all of the responses to treatment i.U s et h em o d e lf o rt h eo n e - w a y\\nlayout to derive E(Yi•)andV(Yi•).\\n13.18 Refer to Exercise 13.17 and consider Yi•−Yi′•fori̸=i′.\\naShow that E(Yi•−Yi′•)=μi−μi′=τi−τi′.T h i sr e s u l ti m p l i e st h a t Yi•−Yi′•is an\\nunbiased estimator of the difference in the effects of treatments iandi′.\\nbDerive V(Yi•−Yi′•).\\n13.19 Refer to the statistical model for the one-waylayout.\\naShow that H0:τ1=τ2=···=τ k=0is equivalent to H0:μ1=μ2=···=μ k.\\nbShow that Ha:τi̸=0for at least one iis equivalent to Ha:μi̸=μi′for some i̸=i′.\\n13.6 Proof of Additivity of the Sums of Squares\\nandE(MST) for a One-Way\\nLayout (Optional)\\nThe proof that\\nTotal SS =SST+SSE\\nfor the one-waylayout is presented in this section for the beneﬁt of those who are\\ninterested. It maybe omitted without loss of continuity.\\nThe proof uses elementaryresults on summations that appear in the e xercises for\\nChapter 1 and the device of adding and subtracting Yi•within the e xpression for the\\nTotal SS. Thus,\\nTotal SS =k∑\\ni=1ni∑\\nj=1(Yij−Y)2=k∑\\ni=1ni∑\\nj=1(Yij−Yi•+Yi•−Y)2\\n=k∑\\ni=1ni∑\\nj=1[(Yij−Yi•)+(Yi•−Y)]2\\n=k∑\\ni=1ni∑\\nj=1[(Yij−Yi•)2+2(Yij−Yi•)(Yi•−Y)+(Yi•−Y)2].\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n680 Chapter 13 The Analysis of Variance\\nSumming ﬁrst over j,w eo b t a i n\\nTotal SS =k∑\\ni=1[ni∑\\nj=1(Yij−Yi•)2+2(Yi•−Y)ni∑\\nj=1(Yij−Yi•)+ni(Yi•−Y)2]\\n,\\nwhere\\nni∑\\nj=1(Yij−Yi•)=Yi•−niYi•=Yi•−Yi•=0.\\nConsequently,t h em i d d l et e r mi nt h ee xpression for the Total SS is equal to zero.\\nThen, summing over i,w eo b t a i n\\nTotal SS =k∑\\ni=1ni∑\\nj=1(Yij−Yi•)2+k∑\\ni=1ni(Yi•−Y)2=SSE+SST.\\nProof of the additivityof the ANOV A sums of squares for other e xperimental\\ndesigns can be obtained in a similar manner although the procedure is often tedious.\\nWe now proceed with the derivation of the e xpected value of MST for a one-way\\nlayout (including a completelyrandomized design). Using the statistical model for\\nthe one-waylayout presented in Section 13.5, it follows that\\nYi•=1\\nnini∑\\nj=1Yij=1\\nnini∑\\nj=1(μ+τi+εij)=μ+τi+εi, where εi=1\\nnini∑\\nj=1εij.\\nBecause the εij’s are independent random variables with E(εij)=0and V(εij)=σ2,\\nTheorem 5.12 implies (see Example 5.27) that E(εi)=0and V(εi)=σ2/ni.\\nIn a completelyanalogous manner, Yis given by\\nY=1\\nnk∑\\ni=1ni∑\\nj=1Yij=1\\nnk∑\\ni=1ni∑\\nj=1(μ+τi+εij)=μ+τ+ε,\\nwhere\\nτ=1\\nnk∑\\ni=1niτiand ε=1\\nnk∑\\ni=1ni∑\\nj=1εij.\\nSince the τivalues are constants, τis simplyac o n s t a n t ;a g a i nu s i n gT h e o r e m5 . 1 2 ,\\nwe obtain E(ε)=0and V(ε)=σ2/n.\\nTherefore, with respect to the terms in the model for the one-waylayout,\\nMST=(1\\nk−1)k∑\\ni=1ni(Yi•−Y)2=(1\\nk−1)k∑\\ni=1ni(τi+εi−τ−ε)2\\n=(1\\nk−1)k∑\\ni=1ni(τi−τ)2+(1\\nk−1)k∑\\ni=12ni(τi−τ)(εi−ε)\\n+(1\\nk−1)k∑\\ni=1ni(εi−ε)2.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.'),\n"," Document(metadata={}, page_content='658 Chapter 12 Considerations in Designing Experiments\\n12.30 What factors affect the quantityof information in an e xperiment? What design procedures\\ncontrol these factors?\\n12.31 Refer to the matched-pairs e xperiment of Section 12.3 and assume that the measurement\\nreceiving treatment i,w h e r e i=1,2, in the jth pair, where j=1,2,...,n ,i s\\nYij=μi+Pj+εij,\\nwhere μi=expected response for treatment i,f o ri=1,2,\\nPj=additive random effect (positive or negative) contribution bythe jth\\npair of e xperimental units, for j=1,2,...,n ,\\nεij=random error associated with the e xperimental unit in the jth pair that\\nreceives treatment i.\\nAssume that the εij’s are independent normal random variables with E(εij)=0,V(εij)=σ2;\\nand assume that the Pj’s are independent normal random variables with E(Pj)=0,V(Pj)=\\nσ2\\np.A l s o ,a s s u m et h a tt h e Pj’s and εij’s are independent.\\naFind E(Yij).\\nbFind E(Yi)andV(Yi),w h e r e Yiis the mean of the nobservations receiving treatment i,\\nwhere i=1,2.\\ncLetD=Y1−Y2.F i n d E(D),V(D),a n dt h ep r o b a b i l i t ydistribution for D.\\n12.32 Refer to Exercise 12.31. Prove that\\nD√n\\nSD\\npossesses a tdistribution, under H0:(μ1−μ2)=0.\\n*12.33 Refer to Exercise 12.31. Suppose that a completelyrandomized design is emplo yed for\\nthe comparison of the two treatment means. Then, a response could be modeled bythe\\nexpression\\nYij=μi+Pij+εij,\\nbut the “pair effect” Pij(which will still affect an e xperimental unit) will be randomlyse-\\nlected and will likelydiffer from one of the 2n observations to another. Further, in contrast to\\nthe matched-pairs e xperiment, the pair effects will not cancel when you calculate (Y1−Y2).\\nCompare V(Y1−Y2)=V(D)for this design with the matched-pairs design of Exercise 12.31.\\nWhyis the variance for the completelyrandomized design usuallylarger?1\\n12.34 Persons submitting computing jobs to a computer center usuallyare required to estimate the\\namount of computer time required to complete the job. This time is measured in CPUs, the\\namount of time that a job will occup yap o r t i o no ft h ec o m p u t e r ’ sc e n t r a lp r o c e s s i n gu n i t ’ s\\nmemory.Ac o m p u t e rc e n t e rd e c i d e dt op e r f o r mac o m p a r i s o no ft h ee s t i m a t e dv e r s u sa c t u a l\\nCPU times for a particular customer. The corresponding times were available for 11 jobs. The\\nsample data are given in the accompan ying table.\\n1.Exercises preceded byan asterisk are optional.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\nSupplementary Exercises 659\\nJob Number\\nCPU Time\\n(minutes) 1 2 3 45 6 7 8 91 011\\nEstimated .501.40.95 .45 .75 1.201.602.6 1.30.85 .60\\nActual .46 1.52 .99 .53 .71 1.31 1.49 2.9 1.41 .83 .74\\naWhywould you e xpect that the observations within each of these pairs of data to be\\ncorrelated?\\nbDo the data provide sufﬁcient evidence to indicate that, on the average, the customer tends\\nto underestimate the CPU time required for computing jobs? Test using α=.10.\\ncFind the observed signiﬁcance level for the test and interpret its value.\\ndFind a 9 0%c o n ﬁ d e n c ei n t e r v a lf o rt h ed i f f e r e n c ei nm e a ne s t i m a t e dC P Ut i m ev e r s u sm e a n\\nactual CPU time.\\n12.35 The earth’s temperature affects seed germination, crop survival in inclement weather, and man y\\nother aspects of agricultural production. Temperature at various locations can be measured\\nusing ground-based sensors or infrared-sensing devices mounted on aircraft or space satellites.\\nGround-based sensoring is tedious and requires man yreplications to obtain accurate estimates\\nof ground temperature. On the other hand, airplane- or satellite-mounted sensors appear to\\nintroduce a bias in temperature readings. To estimate the amount of bias, both methods were\\nused to measure ground temperature at ﬁve locations. The readings, measured in degrees\\nCelsius, are given in the following table.\\nTemperature (◦C)\\nLocation Ground Air\\n14 6 . 9 47.3\\n24 5 . 4 48.1\\n33 6 . 3 37.9\\n43 1 . 032.7\\n52 4 . 7 26.2\\naDo the data present sufﬁcient evidence to claim a difference in average ground-temperature\\nreadings using ground- and air-based sensors?\\nbConstruct a 95% conﬁdence interval for the difference in mean ground-temperature read-\\nings using ground- and air-based sensors.\\ncWe want to estimate the difference between mean temperature readings for ground- and\\nair-based sensors to within .2◦Ca tt h e9 5 %c o n ﬁ d e n c el e v e l .A p p r o ximatelyhow man y\\npaired observations (measurements at different locations) are required?\\n12.36 An e xperiment was conducted to compare mean reaction time to two types of trafﬁc signs:\\nprohibitive (no left turn) and permissive (left turn only). Ten subjects were included in the\\nexperiment. Each subject was presented 40trafﬁc signs, 20prohibitive and 20permissive, in\\nrandom order. The mean time to reaction and the number of correct actions were recorded for\\neach subject. The mean reaction times to the 20prohibitive and 20permissive trafﬁc signs for\\neach of the ten subjects are reproduced in the following table.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n660 Chapter 12 Considerations in Designing Experiments\\nMean Reaction Times (ms)\\nfor 20Trafﬁc Signs\\nSubject Prohibitive Permissive\\n18 2 4 702\\n28 6 6 725\\n38 4 1 744\\n47 7 0663\\n58 2 9 792\\n67 6 4 708\\n78 5 7 747\\n88 3 1 685\\n98 4 6 742\\n10759 610\\naExplain whythis is a matched-pairs e xperiment and give reasons whythe pairing should\\nbe useful in increasing information on the difference between the mean reaction times to\\nprohibitive and permissive trafﬁc signs.\\nbDo the data present sufﬁcient evidence to indicate a difference in mean reaction times to\\nprohibitive and permissive trafﬁc signs? Test using α=.05.\\ncFind and interpret the approximate p-value for the test in part (b).\\ndFind a 95% conﬁdence interval for the difference in mean reaction times to prohibitive and\\npermissive trafﬁc signs.\\n*12.37 Suppose that you wish to ﬁt the model\\nY=β0+β1x+β2x2+ε\\nto a set of ndata points. If the npoints are to be allocated at the design points x=−1,0,a n d\\n1, what fraction should be assigned to each value of xso as to minimize V(ˆβ2)?( A s s u m et h a t\\nnis large and that k1,k2,a n dk 3,k1+k2+k3=1, are the fractions of the total number of\\nobservations to be assigned at x=−1,0,a n d1 ,r e s p e c t i v e l y.)\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\nCHAPTER 13\\nThe Analysis of Variance\\n13.1 Introduction\\n13.2 The Analysis of Variance Procedure\\n13.3 Comparison of More Than Two Means: Analysis of Variance\\nfor a One-Way Layout\\n13.4 An Analysis of Variance Table for a One-Way Layout\\n13.5 AS t a t i s t i c a lM o d e lf o rt h eO n e - W a yL a y o u t\\n13.6 Proof of Additivity of the Sums of Squares and E(MST) for a One-Way\\nLayout (Optional)\\n13.7 Estimation in the One-Way Layout\\n13.8 AS t a t i s t i c a lM o d e lf o rt h eR a n d o m i z e dB l o c kD e s i g n\\n13.9 The Analysis of Variance for a Randomized Block Design\\n13.10 Estimation in the Randomized Block Design\\n13.11 Selecting the Sample Size\\n13.12 Simultaneous Conﬁdence Intervals for More Than One Parameter\\n13.13 Analysis of Variance Using Linear Models\\n13.14 Summary\\nReferences and Further Readings\\n13.1 Introduction\\nMost e xperiments involve a studyof the effect of one or more independent variables\\non a response. Independent variables that can be controlled in an e xperiment are called\\nfactors,a n dt h ei n t e n s i t ylevel of a factor is called its level.\\nThe analysis of data generated byam u l t i v a r i a b l ee xperiment requires identiﬁca-\\ntion of the independent variables in the e xperiment. These will not onlybe factors\\n(controlled independent variables) but could also be directions of blocking. If one\\n661\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.'),\n"," Document(metadata={}, page_content='Supplementary Exercises 709\\naCalculate the sums of squares for this e xperiment and construct an ANOV A table.\\nbHow man ydegrees of freedom are associated with SSE?\\ncDo the data present sufﬁcient evidence to indicate a difference in the mean uptake of calcium\\nfor the three levels of digitalis?\\ndDo the data indicate a difference in the mean uptake in calcium for the heart muscles of\\nthe four dogs?\\neGive the standard deviation of the difference between the mean calcium uptakes for two\\nlevels of digitalis.\\nfFind a 95% conﬁdence interval for the difference in mean responses between treatments\\nAa n dB .\\n13.84 Refer to Exercise 13.83. Approximatelyhow man yreplications are required for each level of\\ndigitalis (how man yblocks) so that the error of estimating the difference in mean response for a\\npair of digitalis levels is less than 2 0,w i t hp r o b a b i l i t y.95? Assume that additional observations\\nwould be made within a randomi zed block design.\\n13.85 Ac o m p l e t e l yrandomized design was conducted to compare the effects of ﬁve stimuli on reac-\\ntion time. Twenty-seven people were emplo yed in the e xperiment, which was conducted using a\\ncompletelyrandomized design. Regardless of the results of the ANOV A, it is desired to compare\\nstimuli A and D. The reaction times (in seconds) were as shown in the accompan ying table.\\nStimulus\\nABCD E\\n.8 .7 1.2 1.0.6\\n.6 .8 1. 0.9 .4\\n.6 .5 .9 .9 .4\\n.5 .5 1.2 1.1 .7\\n.6 1.3 .7 .3\\n.9 .8\\n.7\\nTotal 2.5 4.7 6.4 4.6 2.4\\nMean .625 .671 1.067 .920.480\\naConduct an ANOV A and test for a difference in mean reaction times due to the ﬁve stimuli.\\nGive bounds for the p-value.\\nbCompare stimuli A and D to see if there is a difference in mean reaction times. What can\\nbe said about the attained signiﬁcance level?\\n13.86 Because we would e xpect mean reaction time to varyfrom one person to another, the e xper-\\niment in Exercise 13.85 might have been conducted more effectivel ybyusing a randomized\\nblock design with people as blocks. Hence, four people were used in a new e xperiment, and\\neach person was subjected to each of the ﬁve stimuli in a random order. The reaction times (in\\nseconds) were as shown in the accompan ying table. Conduct an ANOV A and test for differences\\nin mean reaction times for the four stimuli.\\nStimulus\\nSubject A B C D E\\n1. 7 . 8 1 . 01.0.5\\n2. 6 . 6 1 . 1 1 . 0.6\\n3. 9 1 . 01.2 1.1 .6\\n4. 6 . 8 . 9 1 . 0.4\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n710 Chapter 13 The Analysis of Variance\\n13.87 Refer to Exercise 13.46. Construct conﬁdence intervals to compare each of the ryegrass culti-\\nvars with Marvelgreen supreme in such a wa ythat the simultaneous conﬁdence coefﬁcient is\\nat least .95. Interpret the results.\\n13.88 Show that\\nTotal SS =SST+SSB+SSE\\nfor a randomized block design, where\\nSSE=b∑\\nj=1k∑\\ni=1(Yij−Y•j−Yi•+Y)2.\\n*13.89 Consider the following model for the responses measured in a randomized block design con-\\ntaining bblocks and ktreatments:\\nYij=μ+τi+βj+εij,\\nwhere Yij=response to treatment iin block j,\\nμ=overall mean,\\nτi=nonrandom effect of treatment i,w h e r e∑k\\ni=1τi=0,\\nβj=random effect of block j,w h e r eβ j’s are independent, normall y\\ndistributed random variables with E(βj)=0and V(βj)=σ2\\nβ,f o r\\nj=1,2,...,b ,\\nεij=random error terms where εij’s are independent, normall ydistributed\\nrandom variables with E(εij)=0and V(εij)=σ2\\nε,f o ri=1,2,...,k\\nandj=1,2,...,b .\\nFurther, assume that the βj’s and εij’s also are independent. This model differs from that pre-\\nsented in Section 13.8 in that the block effects are assumed to be random variables instead of\\nﬁxed but unknown constants.\\naIf the model just described is appropriate, show that observations taken from different\\nblocks are independent of one another. That is, show that YijandYij′are independent if\\nj̸=j′,a sa r e YijandYi′j′ifi̸=i′andj̸=j′.\\nbUnder the model just described, derive the covariance of two observations from the same\\nblock. That is, ﬁnd Cov( Yij,Yi′j)ifi̸=i′.\\ncTwo random variables that have a joint normal distribution are independent if and onl yif\\ntheir covariance is 0.U s et h er e s u l tf r o mp a r t( b )t od e t e r m i n ec o n d i t i o n su n d e rw h i c ht w o\\nobservations from the same block are independent of one another.\\n*13.90 Refer to the model for the randomi zed block design with random block effect given in\\nExercise 13.89.\\naGive the e xpected value and variance of Yij.\\nbLetYi•denote the average of all of the responses to treatment i.U s et h em o d e lf o rt h e\\nrandomized block design to derive E(Yi•)andV(Yi•).I sYi•an unbiased estimator for the\\nmean response to treatment i?W h yor whynot? Notice that V(Yi•)depends on band both\\nσ2\\nβandσ2\\nε.\\ncConsider Yi•−Yi′•fori̸=i′.S h o wt h a t E(Yi•−Yi′•)=τi−τi′.T h i sr e s u l ti m p l i e st h a t\\nYi•−Yi′•is an unbiased estimator of the difference in the effects of treatments iandi′.\\ndDerive V(Yi•−Yi′•).N o t i c et h a t V(Yi•−Yi′•)depends onlyon bandσ2\\nε.\\n*13.91 Refer to the model for the randomized block design with random block effect given in\\nExercise 13.89 and let Y•jdenote the average of all the responses in block j.D e r i v e\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\nSupplementary Exercises 711\\naE(Y•j)andV(Y•j).\\nbE(MST).\\ncE(MSB).\\ndE(MSE).\\n*13.92 Refer to the model for the randomized block design with random block effect given in Exercise\\n13.89 and the results obtained in Exercise 13.91(c) and (d). Give an unbiased estimator for\\naσ2\\nε.\\nbσ2\\nβ.\\n*13.93 Suppose that Y1,Y2,...,Y nis a random sample from a normal distribution with mean μand\\nvariance σ2.T h ei n d e p e n d e n c eo f∑n\\ni=1(Yi−Y)2andYcan be shown as follows. Deﬁne an\\nn×nmatrix Aby\\nA=⎡\\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣1√n1√n1√n1√n···1√n1√n\\n1√\\n2−1√\\n200 ··· 00\\n1√\\n2·31√\\n2·3−2√\\n2·30··· 00\\n.....................\\n1√(n−1)n1√(n−1)n···1√(n−1)n−(n−1)√(n−1)n⎤\\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦\\nand notice that A′A=I,t h ei d e n t i t ymatrix.T h e n ,\\nn∑\\ni=1Y2\\ni=Y′Y=Y′A′AY,\\nwhere Yis the vector of Yivalues.\\naShow that\\nAY=⎡\\n⎢⎢⎢⎢⎢⎢⎢⎣Y√n\\nU1\\nU2\\n...\\nUn−1⎤\\n⎥⎥⎥⎥⎥⎥⎥⎦,\\nwhere U1,U2,..., Un−1are linear functions of Y1,Y2,...,Y n.T h u s ,\\nn∑\\ni=1Y2\\ni=nY2+n−1∑\\ni=1U2\\ni.\\nbShow that the linear functions Y√n,U1,U2,..., Un−1are pairwise orthogonal and hence\\nindependent under the normalityassumption. (See Exercise 5.130.)\\ncShow that\\nn∑\\ni=1(Yi−Y)2=n−1∑\\ni=1U2\\ni\\nand conclude that this quantityis independent of Y.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n712 Chapter 13 The Analysis of Variance\\ndUsing the results of part (c), show that\\n∑n\\ni=1(Yi−Y)2\\nσ2=(n−1)S2\\nσ2\\nhas a χ2distribution with (n−1)df.\\n13.94 Consider a one-waylayout with ktreatments. Assume that Yijis the jth response for treat-\\nment (population) iand that Yijis normallydistributed with mean μiand variance σ2,f o r\\ni=1,2,...,k andj=1,2,...,n i.\\naUse Exercise 13.93 to justifythat Y1,Y2,..., Ykare independent of SSE.\\nbShow that MST/MSE has an Fdistribution with ν1=k−1a n dν 2=n1+n2+···+\\nnk−kdf under H0:μ1=μ2=· · ·=μ k.( Y o um a yassume, for simplicity,t h a t\\nn1=n2=···=n k.)\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.'),\n"," Document(metadata={}, page_content='13.7 Estimation in the One-Way Layout 681\\nBecause τandτi,f o ri=1,2,...,k ,a r ec o n s t a n t sa n d E(εij)=E(εi)=E(ε)=0,\\nit follows that\\nE(MST) =(1\\nk−1)k∑\\ni=1ni(τi−τ)2+(1\\nk−1)\\nE[k∑\\ni=1ni(εi−ε)2]\\n.\\nNotice that\\nk∑\\ni=1ni(εi−ε)2=k∑\\ni=1(\\nniε2\\ni−2niεiε+niε2)\\n=k∑\\ni=1niε2\\ni−2nε2+nε2=k∑\\ni=1niε2\\ni−nε2.\\nBecause E(εi)=0and V(εi)=σ2/ni,i tf o l l o w st h a t E(ε2\\ni)=σ2/ni,f o r i=\\n1,2,...,k .S i m i l a r l y,E(ε2)=σ2/n,a n d ,h e n c e ,\\nE[k∑\\ni=1ni(εi−ε)2]\\n=k∑\\ni=1niE(\\nε2\\ni)\\n−nE(\\nε2)\\n=kσ2−σ2=(k−1)σ2.\\nSummarizing, we obtain\\nE(MST) =σ2+(1\\nk−1)k∑\\ni=1ni(τi−τ)2, where τ=1\\nnk∑\\ni=1niτi.\\nUnder H0:τ1=τ2=···=τ k=0,i tf o l l o w st h a t τ=0,a n d ,h e n c e , E(MST) =\\nσ2.T h u s ,w h e n H0is true, MST/ MSE is the ratio of two unbiased estimators for σ2.\\nWhen Ha:τi̸=0for some i,1≤i≤kis true, the quantity1 /(k−1)∑k\\ni=1ni(τi−\\nτ)2is strictlypositive and MST is a positivelybiased estimator for σ2.\\n13.7 Estimation in the One-Way Layout\\nConﬁdence intervals for a single treatment mean and for the difference between a\\npair of treatment means based on data obtained in a one-waylayout (Section 13.3)\\nare completelyanalogous to those given in Chapter 8. The onlydifference between\\nthe intervals in Chapter 8 and those that follow is that intervals associated with\\nthe one-waylayout use MSE (the pooled estimator based on all ksamples) to esti-\\nmate the population variance(s) σ2.T h ec o n ﬁ d e n c ei n t e r v a lf o rt h em e a no ft r e a t -\\nment ior the difference between the means for treatments iandi′are, respectively,\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\n682 Chapter 13 The Analysis of Variance\\nas follows:\\nYi•±tα/2S√ni,\\nand\\n(Yi•−Yi′•)±tα/2S√\\n1\\nni+1\\nni′,\\nwhere\\nS=√\\nS2=√\\nMSE=√\\nSSE\\nn1+n2+···+n k−k\\nandtα/2is based on (n−k)df.\\nThe conﬁdence intervals just stated are appropriate for a single treatment mean\\nor a comparison of a pair of means selected prior to observation of the data. These\\nintervals are likelyto be shorter than the corresponding intervals from Chapter 8\\nbecause the value of tα/2is based on a greater number of degrees of freedom (n −k\\ninstead of ni−1o rn i+ni′−2, respectively). The stated conﬁdence coefﬁcients are\\nappropriate for a single mean or difference in two means identiﬁed prior to observing\\nthe actual data .I fw ew e r et ol o o ka tt h ed a t aa n da l w a ysc o m p a r et h ep o p u l a t i o n s\\nthat produced the largest and smallest sample means, we would e xpect the difference\\nbetween these sample means to be larger than for a pair of means speciﬁed to be of\\ninterest before observing the data.\\nEXAMPLE 13.3 Find a 95% conﬁdence interval for the mean score for teaching technique 1, Example\\n13.2.\\nSolution The 95% conﬁdence interval for the mean score is\\nY1•±t.025S√n1,\\nwhere t.025is determined for n−k=19 df, or\\n75.67±(2.093)√\\n63√\\n6or 75. 67±6.78.\\nNotice that if we had analyzed onlythe data for teaching technique 1, the value of\\nt.025would have been based on onl yn1−1=5d f ,t h en u m b e ro fd e g r e e so ff r e e d o m\\nassociated with s1.\\nEXAMPLE 13.4 Find a 95% conﬁdence interval for the difference in mean score for teaching techniques\\n1a n d4 ,E xample 13.2.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\\n\\nExercises 683\\nSolution The 95% conﬁdence interval is\\n(Y1•−Y4•)±(2.093)(7 .94)√\\n1/6+1/4o r −12.08±10.73.\\nHence, the 95% conﬁdence interval for (μ1−μ4)is(−22.81,−1.35).A tt h e9 5 %\\nconﬁdence level we conclude that μ4>μ 1byat least 1.35 but no more than 22.81.\\nExercises\\n13.20 Refer to Examples 13.2 and 13.3.\\naUse the portion of the data in Table 13.2 that deals onlywith teaching technique 1 and the\\nmethod of Section 8.8 to form a 95% conﬁdence interval for the mean score of students\\ntaught using technique 1.\\nbHow does the length of the 95% conﬁdence interval that you found in part (a) compare to\\nthe length of the 95% conﬁdence interval obtained in E xample 13.3?\\ncWhat is the major reason that the interval that you found in part (a) is longer than the\\ninterval given in Example 13.3?\\n13.21 Refer to Examples 13.2 and 13.4.\\naUse the portion of the data in Table 13.2 that deals onlywith teaching techniques 1 and 4\\nand the method of Section 8.8 to form a 95% conﬁdence interval for the difference in mean\\nscore for students taught using techniques 1 and 4.\\nbHow does the length of the 95% conﬁdence interval that you found in part (a) compare to\\nthe length of the 95% conﬁdence interval obtained in Example 13.4?\\ncWhat is the major reason that the interval that you found in part (a) is longer than the\\ninterval given in Example 13.4?\\n13.22 aBased on your answers to Exercises 13.20and 13.21 and the comments at the end of this\\nsection, how would you e xpect conﬁdence intervals computed using the results of this\\nsection to compare with related intervals that make use of the data from onl yone or two of\\nthe samples obtained in a one-wa ylayout? Why?\\nbRefer to part (a). Is it possible that a 95% conﬁdence interval for the mean of a single\\npopulation based onlyon the sample taken from that population will be shorter than the\\n95% conﬁdence interval for the same population mean that would be obtained using the\\nprocedure of this section? How?\\n13.23 Refer to Exercise 13.7.\\naConstruct a 95% conﬁdence interval for the mean amount of polluting efﬂuent per gallon\\nfor plant A. If the limit for the mean amount of polluting efﬂuent is 1.5 pound/gallon, would\\nyou conclude that plant A e xceeds this limit? Why?\\nbGive a 95% conﬁdence interval for the difference in mean polluting efﬂuent per gallon for\\nplants A and D. Does this interval indicate that mean efﬂuent per gallon differs for these\\ntwo plants? Why?\\n13.24 Refer to Exercise 13.8. Construct a 98% conﬁdence interval for the difference in mean starting\\nsalaries for assistant professors at public and private/independent doctoral-granting institutions.\\n      Copyright 2011 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.')]"]},"metadata":{},"execution_count":47}],"source":["result[\"source_documents\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4tnkbUfhcW3","executionInfo":{"status":"ok","timestamp":1727346036190,"user_tz":-330,"elapsed":4014,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"68d39bea-5c64-4759-dcf1-92cae38d37be"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The provided text focuses on the analysis of variance (ANOVA) and doesn\\'t contain information about multi-head attention layers. \\n\\nHowever, I can provide a detailed description of the multi-head attention layer based on my knowledge:\\n\\n**Multi-Head Attention Layer**\\n\\nA multi-head attention layer is a crucial component of transformer-based models, particularly in natural language processing (NLP). It allows the model to attend to different parts of the input sequence from multiple perspectives, enhancing its ability to capture complex relationships and dependencies.\\n\\n**How it works:**\\n\\n1. **Input:** The multi-head attention layer receives an input sequence, typically represented as a matrix of embeddings. Each row in the matrix corresponds to a token in the sequence.\\n\\n2. **Linear Projections:** The input is projected into three different spaces using separate linear transformations:\\n    * **Query (Q):** Represents the \"what\" the model is looking for.\\n    * **Key (K):** Represents the \"where\" the model should look.\\n    * **Value (V):** Represents the \"what\" the model should output.\\n\\n3. **Scaled Dot-Product Attention:** For each head, the scaled dot-product attention mechanism is applied:\\n    * **Calculate Attention Scores:** The query matrix (Q) is multiplied with the transpose of the key matrix (K), resulting in a matrix of attention scores. These scores represent the similarity between each query and each key.\\n    * **Softmax Normalization:** The attention scores are normalized using a softmax function, ensuring that the attention weights for each query sum up to 1.\\n    * **Weighted Sum:** The normalized attention weights are multiplied with the value matrix (V), resulting in a weighted sum of values. This weighted sum represents the output of the attention head.\\n\\n4. **Multiple Heads:** The process described above is repeated for multiple heads, each with its own set of linear projections and attention scores. This allows the model to attend to different aspects of the input sequence simultaneously.\\n\\n5. **Concatenation and Linear Projection:** The outputs from all the attention heads are concatenated and projected into a single output space using another linear transformation.\\n\\n**Benefits of Multi-Head Attention:**\\n\\n* **Multiple Perspectives:**  Each head focuses on different parts of the input, capturing diverse relationships.\\n* **Improved Representation:** The concatenated output from multiple heads provides a richer and more comprehensive representation of the input sequence.\\n* **Parallelism:** The multiple heads can be computed in parallel, speeding up the processing.\\n\\n**Applications:**\\n\\nMulti-head attention layers are widely used in various NLP tasks, including:\\n\\n* **Machine Translation:**  Capturing long-range dependencies between words in different languages.\\n* **Text Summarization:** Identifying important sentences and phrases for summarization.\\n* **Question Answering:** Understanding the relationship between questions and answers.\\n* **Sentiment Analysis:**  Analyzing the emotional tone of text.\\n\\n**In summary, the multi-head attention layer is a powerful mechanism that allows transformer models to effectively attend to different parts of the input sequence from multiple perspectives, leading to improved performance in various NLP tasks.** \\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}],"source":["template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just mention that the data is not from the given document and present the data based on your knowledge. Keep the answer relevant and elaborate it in the depth possible.\n","{context}\n","Question: {question}\n","Helpful Answer:\"\"\"\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    model,\n","    retriever=vector_index,\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","\n","\n","\n","question = \"Describe the Multi-head attention layer in detail?\"\n","result = qa_chain({\"query\": question})\n","result[\"result\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zrQJlCRhrb3","executionInfo":{"status":"ok","timestamp":1727346036190,"user_tz":-330,"elapsed":4,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ba6359a-faa6-4d63-e832-f0babee95cff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The provided text focuses on the analysis of variance (ANOVA) and doesn't contain information about multi-head attention layers. \n\nHowever, I can provide a detailed description of the multi-head attention layer based on my knowledge:\n\n**Multi-Head Attention Layer**\n\nA multi-head attention layer is a crucial component of transformer-based models, particularly in natural language processing (NLP). It allows the model to attend to different parts of the input sequence from multiple perspectives, enhancing its ability to capture complex relationships and dependencies.\n\n**How it works:**\n\n1. **Input:** The multi-head attention layer receives an input sequence, typically represented as a matrix of embeddings. Each row in the matrix corresponds to a token in the sequence.\n\n2. **Linear Projections:** The input is projected into three different spaces using separate linear transformations:\n    * **Query (Q):** Represents the \"what\" the model is looking for.\n    * **Key (K):** Represents the \"where\" the model should look.\n    * **Value (V):** Represents the \"what\" the model should output.\n\n3. **Scaled Dot-Product Attention:** For each head, the scaled dot-product attention mechanism is applied:\n    * **Calculate Attention Scores:** The query matrix (Q) is multiplied with the transpose of the key matrix (K), resulting in a matrix of attention scores. These scores represent the similarity between each query and each key.\n    * **Softmax Normalization:** The attention scores are normalized using a softmax function, ensuring that the attention weights for each query sum up to 1.\n    * **Weighted Sum:** The normalized attention weights are multiplied with the value matrix (V), resulting in a weighted sum of values. This weighted sum represents the output of the attention head.\n\n4. **Multiple Heads:** The process described above is repeated for multiple heads, each with its own set of linear projections and attention scores. This allows the model to attend to different aspects of the input sequence simultaneously.\n\n5. **Concatenation and Linear Projection:** The outputs from all the attention heads are concatenated and projected into a single output space using another linear transformation.\n\n**Benefits of Multi-Head Attention:**\n\n* **Multiple Perspectives:**  Each head focuses on different parts of the input, capturing diverse relationships.\n* **Improved Representation:** The concatenated output from multiple heads provides a richer and more comprehensive representation of the input sequence.\n* **Parallelism:** The multiple heads can be computed in parallel, speeding up the processing.\n\n**Applications:**\n\nMulti-head attention layers are widely used in various NLP tasks, including:\n\n* **Machine Translation:**  Capturing long-range dependencies between words in different languages.\n* **Text Summarization:** Identifying important sentences and phrases for summarization.\n* **Question Answering:** Understanding the relationship between questions and answers.\n* **Sentiment Analysis:**  Analyzing the emotional tone of text.\n\n**In summary, the multi-head attention layer is a powerful mechanism that allows transformer models to effectively attend to different parts of the input sequence from multiple perspectives, leading to improved performance in various NLP tasks.** \n"},"metadata":{},"execution_count":49}],"source":["\n","Markdown(result[\"result\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVAYub7FhuFg"},"outputs":[],"source":["question = \"plane waves and its equation detailed explaination?\"\n","result = qa_chain({\"query\": question})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2_mktSZh8n2","executionInfo":{"status":"ok","timestamp":1727346040746,"user_tz":-330,"elapsed":6,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5598fb09-0d8f-4d33-b3dc-b44227d08b83"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The provided text focuses on linear models and estimation using least squares, not on plane waves. Therefore, I cannot answer your question about plane waves and their equation from the given context. \n\nHowever, I can provide you with a detailed explanation of plane waves and their equation based on my knowledge:\n\n**Plane Waves**\n\nA plane wave is a wave whose wavefronts (surfaces of constant phase) are infinite planes. These waves are characterized by their:\n\n* **Direction of Propagation:** The direction in which the wave travels.\n* **Amplitude:** The maximum displacement of the wave from its equilibrium position.\n* **Frequency:** The number of wave cycles that pass a point per unit time.\n* **Wavelength:** The distance between two successive crests or troughs of the wave.\n\n**Equation of a Plane Wave**\n\nThe general equation for a plane wave traveling in a direction specified by the wave vector **k** is:\n\n**ψ(r, t) = A * cos(k * r - ωt + φ)**\n\nWhere:\n\n* **ψ(r, t):** The wave function, representing the displacement of the wave at position **r** and time **t**.\n* **A:** The amplitude of the wave.\n* **k:** The wave vector, a vector pointing in the direction of wave propagation, with magnitude |k| = 2π/λ (where λ is the wavelength).\n* **r:** The position vector, specifying the location in space.\n* **ω:** The angular frequency, related to the frequency (f) by ω = 2πf.\n* **t:** Time.\n* **φ:** The phase constant, determining the initial phase of the wave.\n\n**Explanation of the Equation:**\n\n* **k * r:** This term represents the dot product of the wave vector and the position vector. It determines the phase of the wave at a given point in space.\n* **ωt:** This term represents the phase shift due to the passage of time.\n* **φ:** This term represents the initial phase of the wave, which is a constant value.\n\n**Types of Plane Waves:**\n\n* **Transverse Plane Waves:** The displacement of the wave is perpendicular to the direction of propagation (e.g., electromagnetic waves).\n* **Longitudinal Plane Waves:** The displacement of the wave is parallel to the direction of propagation (e.g., sound waves).\n\n**Applications of Plane Waves:**\n\nPlane waves are fundamental concepts in physics and have numerous applications, including:\n\n* **Electromagnetic Waves:** Light, radio waves, microwaves, etc.\n* **Sound Waves:** Audible sound, ultrasound, etc.\n* **Seismic Waves:** Waves that travel through the Earth's interior.\n* **Water Waves:** Waves on the surface of water.\n\n**Further Exploration:**\n\nFor a deeper understanding of plane waves, you can explore topics like:\n\n* **Wave Interference:** The superposition of multiple waves.\n* **Wave Diffraction:** The bending of waves around obstacles.\n* **Wave Polarization:** The orientation of the wave's electric field vector.\n\nLet me know if you have any more questions about plane waves or other related topics. \n"},"metadata":{},"execution_count":51}],"source":["Markdown(result[\"result\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCyVR6sChzEw"},"outputs":[],"source":["question = \"Summarize this document in hierircal struture following branch and there sub branch with proper heading and structure\"\n","result = qa_chain({\"query\": question})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FAxHpfDy4WX"},"outputs":[],"source":["def answer_me(question):\n","    result = qa_chain({\"query\": question})\n","    return Markdown(result[\"result\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ky9PjDmYjoRM","executionInfo":{"status":"ok","timestamp":1727346150861,"user_tz":-330,"elapsed":840,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/","height":875},"outputId":"9b72bba3-476b-488e-81cb-468234d156da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"##  Characterizing a Set of Measurements: Graphical Methods\n\n**1. Introduction**\n\n* **Purpose:**  To understand and summarize data using graphical methods.\n* **Key Concept:**  Relative frequency distribution and histograms.\n* **Objective:**  To make inferences from data.\n\n**2. Histograms**\n\n* **Definition:**  A graphical representation of a relative frequency distribution.\n* **Construction:**\n    * Divide the range of data into intervals.\n    * The height of each rectangle represents the relative frequency of the corresponding interval.\n    * The area of each rectangle is proportional to the fraction of measurements in that interval.\n* **Guidelines:**\n    * Choose intervals so that measurements don't fall on division points.\n    * Use 5 to 20 intervals, with more intervals for larger datasets.\n    * Computer software can be used to create histograms.\n\n**3. Probabilistic Interpretation of Histograms**\n\n* **Key Idea:**  The area under the histogram over a given interval represents the probability of selecting a measurement from that interval.\n* **Example:**  If half the measurements fall in an interval, the area under the histogram over that interval is half the total area.\n\n**4. Exercises**\n\n* **Exercise 1.2:**  Analyzing average wind speeds of U.S. cities.\n    * Construct a relative frequency histogram.\n    * Analyze the wind speed of Mt. Washington, NH.\n    * Compare Chicago's wind speed to other cities.\n* **Exercise 1.3:**  Analyzing radioactive material in soil samples.\n    * Construct a relative frequency histogram.\n* **Exercise 1.4:**  Analyzing stock trading activity.\n    * Construct a relative frequency histogram.\n    * Calculate the proportion of stocks trading above a certain threshold.\n    * Calculate the probability of selecting a stock with a certain trading activity.\n* **Exercise 1.5:**  Analyzing student GPA data.\n    * Identify the GPA category with the largest proportion of students.\n    * Calculate the proportion of students in each category.\n    * Calculate the proportion of students with GPAs below a certain value.\n* **Exercise 1.6:**  Analyzing milk purchase data.\n    * Identify the modal category (most frequent).\n    * Calculate the proportion of families purchasing above a certain amount of milk.\n    * Calculate the proportion of families purchasing within a specific range.\n\n**5. Conclusion**\n\n* **Importance:**  Histograms provide a visual representation of data and allow for probabilistic interpretations.\n* **Further Exploration:**  Other graphical methods exist for summarizing data. \n"},"metadata":{},"execution_count":60}],"source":["Markdown(result[\"result\"])"]},{"cell_type":"code","source":["!pip install networkx pyvis"],"metadata":{"id":"acmE9VQl5pP3","executionInfo":{"status":"ok","timestamp":1727346046911,"user_tz":-330,"elapsed":2796,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"319689ed-7360-4c96-8963-5f5b07064a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: pyvis in /usr/local/lib/python3.10/dist-packages (0.3.2)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.4)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.3.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (71.0.4)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n"]}]},{"cell_type":"code","source":["import re\n","from graphviz import Digraph\n","\n","def parse_markdown_to_tree(markdown_text):\n","    \"\"\"\n","    Parses Markdown text with a hierarchical structure into a tree-like graph.\n","\n","    Args:\n","        markdown_text: The Markdown text to parse.\n","\n","    Returns:\n","        A graphviz Digraph object representing the parsed tree structure.\n","    \"\"\"\n","\n","    # Initialize the graph with enhanced styling\n","    dot = Digraph(comment='Enhanced Markdown Tree')\n","\n","    # Set graph attributes for improved visuals\n","    dot.attr(rankdir='LR', splines='curved')  # Left-to-right layout, curved edges\n","    dot.attr('node', shape='box', style='rounded, filled', color='#A9CCE3', fontname='Helvetica', fontsize='10', width='1', height='0.5')  # Node styling\n","    dot.attr('edge', color='#2E86C1', arrowhead='open', arrowsize='0.7')  # Edge styling\n","\n","    # Split the text into lines\n","    lines = markdown_text.strip().split('\\n')\n","\n","    # Stack to maintain parent nodes based on indentation\n","    stack = [('root', 0)]  # (node_id, level)\n","    dot.node('root', 'Root', fillcolor='#5499C7')  # Styled root node\n","\n","    # Regular expression to match heading levels or bullet points\n","    heading_pattern = re.compile(r'^(#+)\\s+(.*)')\n","    bullet_pattern = re.compile(r'^(\\*|\\-|\\+)\\s+(.*)')\n","\n","    for line in lines:\n","        line = line.strip()\n","        if not line:\n","            continue  # Skip empty lines\n","\n","        # Determine the level of indentation\n","        if match := heading_pattern.match(line):\n","            level = len(match.group(1))  # Number of # symbols\n","            text = match.group(2)  # Extract the actual text\n","        elif match := bullet_pattern.match(line):\n","            level = 1  # Bullets treated as level 1\n","            text = match.group(2)\n","        else:\n","            level = 1  # Treat other unformatted lines as level 1\n","            text = line\n","\n","        # Generate a unique node id for each line\n","        node_id = f'node_{len(dot.body)}'\n","        # Add a node with enhanced style based on its depth/level\n","        node_color = '#5DADE2' if level == 1 else '#AED6F1'\n","        dot.node(node_id, text, fillcolor=node_color)  # Add the node with the line's text\n","\n","        # Maintain hierarchy based on level (indentation)\n","        while stack and stack[-1][1] >= level:\n","            stack.pop()  # Pop stack to find the correct parent node\n","\n","        parent_node = stack[-1][0]  # The top of the stack is the parent\n","        dot.edge(parent_node, node_id)  # Add edge from parent to current node\n","\n","        # Push the current node and its level onto the stack\n","        stack.append((node_id, level))\n","\n","    return dot\n","\n","\n","# Assuming 'result[\"result\"]' contains the Markdown text\n","markdown_text = result[\"result\"]\n","\n","# Parse the Markdown text into a tree-like graph\n","graph = parse_markdown_to_tree(markdown_text)\n","\n","# Render and display the graph with enhanced visuals\n","display(graph)\n"],"metadata":{"id":"0OZ-nIa1tkIi","executionInfo":{"status":"ok","timestamp":1727346046911,"user_tz":-330,"elapsed":12,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eae10940-6dc5-4d21-80f8-c73b760bded7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"729pt\" height=\"2150pt\"\n viewBox=\"0.00 0.00 729.00 2150.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2146)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-2146 725,-2146 725,4 -4,4\"/>\n<!-- root -->\n<g id=\"node1\" class=\"node\">\n<title>root</title>\n<path fill=\"#5499c7\" stroke=\"#a9cce3\" d=\"M60,-1089C60,-1089 12,-1089 12,-1089 6,-1089 0,-1083 0,-1077 0,-1077 0,-1065 0,-1065 0,-1059 6,-1053 12,-1053 12,-1053 60,-1053 60,-1053 66,-1053 72,-1059 72,-1065 72,-1065 72,-1077 72,-1077 72,-1083 66,-1089 60,-1089\"/>\n<text text-anchor=\"middle\" x=\"36\" y=\"-1068.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Root</text>\n</g>\n<!-- node_4 -->\n<g id=\"node2\" class=\"node\">\n<title>node_4</title>\n<path fill=\"#aed6f1\" stroke=\"#a9cce3\" d=\"M538.5,-2142C538.5,-2142 290.5,-2142 290.5,-2142 284.5,-2142 278.5,-2136 278.5,-2130 278.5,-2130 278.5,-2118 278.5,-2118 278.5,-2112 284.5,-2106 290.5,-2106 290.5,-2106 538.5,-2106 538.5,-2106 544.5,-2106 550.5,-2112 550.5,-2118 550.5,-2118 550.5,-2130 550.5,-2130 550.5,-2136 544.5,-2142 538.5,-2142\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-2121.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Characterizing a Set of Measurements: Graphical Methods</text>\n</g>\n<!-- root&#45;&gt;node_4 -->\n<g id=\"edge1\" class=\"edge\">\n<title>root&#45;&gt;node_4</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.25,-1089.09C166.1,-1794.9 171.37,-1816.14 395.54,-2100.01\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"400.2,-2105.91 393.39,-2102.37 398.03,-2103.16 395.86,-2100.41 395.86,-2100.41 395.86,-2100.41 398.03,-2103.16 398.33,-2098.46 400.2,-2105.91 400.2,-2105.91\"/>\n</g>\n<!-- node_6 -->\n<g id=\"node3\" class=\"node\">\n<title>node_6</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M449.5,-2088C449.5,-2088 379.5,-2088 379.5,-2088 373.5,-2088 367.5,-2082 367.5,-2076 367.5,-2076 367.5,-2064 367.5,-2064 367.5,-2058 373.5,-2052 379.5,-2052 379.5,-2052 449.5,-2052 449.5,-2052 455.5,-2052 461.5,-2058 461.5,-2064 461.5,-2064 461.5,-2076 461.5,-2076 461.5,-2082 455.5,-2088 449.5,-2088\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-2067.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**1. Introduction**</text>\n</g>\n<!-- root&#45;&gt;node_6 -->\n<g id=\"edge2\" class=\"edge\">\n<title>root&#45;&gt;node_6</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.44,-1089.19C165.76,-1757.38 171.31,-1778.59 394.53,-2046.09\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"399.17,-2051.65 392.27,-2048.3 396.93,-2048.96 394.68,-2046.28 394.68,-2046.28 394.68,-2046.28 396.93,-2048.96 397.1,-2044.26 399.17,-2051.65 399.17,-2051.65\"/>\n</g>\n<!-- node_8 -->\n<g id=\"node4\" class=\"node\">\n<title>node_8</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M573,-2034C573,-2034 256,-2034 256,-2034 250,-2034 244,-2028 244,-2022 244,-2022 244,-2010 244,-2010 244,-2004 250,-1998 256,-1998 256,-1998 573,-1998 573,-1998 579,-1998 585,-2004 585,-2010 585,-2010 585,-2022 585,-2022 585,-2028 579,-2034 573,-2034\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-2013.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Purpose:** &#160;To understand and summarize data using graphical methods.</text>\n</g>\n<!-- root&#45;&gt;node_8 -->\n<g id=\"edge3\" class=\"edge\">\n<title>root&#45;&gt;node_8</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.67,-1089.43C165.41,-1720.01 171.25,-1741.08 393.53,-1992.33\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"398.49,-1997.92 391.49,-1994.77 396.17,-1995.3 393.85,-1992.68 393.85,-1992.68 393.85,-1992.68 396.17,-1995.3 396.21,-1990.6 398.49,-1997.92 398.49,-1997.92\"/>\n</g>\n<!-- node_10 -->\n<g id=\"node5\" class=\"node\">\n<title>node_10</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M553.5,-1980C553.5,-1980 275.5,-1980 275.5,-1980 269.5,-1980 263.5,-1974 263.5,-1968 263.5,-1968 263.5,-1956 263.5,-1956 263.5,-1950 269.5,-1944 275.5,-1944 275.5,-1944 553.5,-1944 553.5,-1944 559.5,-1944 565.5,-1950 565.5,-1956 565.5,-1956 565.5,-1968 565.5,-1968 565.5,-1974 559.5,-1980 553.5,-1980\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1959.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Key Concept:** &#160;Relative frequency distribution and histograms.</text>\n</g>\n<!-- root&#45;&gt;node_10 -->\n<g id=\"edge4\" class=\"edge\">\n<title>root&#45;&gt;node_10</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.86,-1089.3C165.02,-1682.75 171.13,-1703.56 392.52,-1938.69\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"397.46,-1943.93 390.37,-1940.99 395.06,-1941.38 392.66,-1938.83 392.66,-1938.83 392.66,-1938.83 395.06,-1941.38 394.95,-1936.67 397.46,-1943.93 397.46,-1943.93\"/>\n</g>\n<!-- node_12 -->\n<g id=\"node6\" class=\"node\">\n<title>node_12</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M509.5,-1926C509.5,-1926 319.5,-1926 319.5,-1926 313.5,-1926 307.5,-1920 307.5,-1914 307.5,-1914 307.5,-1902 307.5,-1902 307.5,-1896 313.5,-1890 319.5,-1890 319.5,-1890 509.5,-1890 509.5,-1890 515.5,-1890 521.5,-1896 521.5,-1902 521.5,-1902 521.5,-1914 521.5,-1914 521.5,-1920 515.5,-1926 509.5,-1926\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1905.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Objective:** &#160;To make inferences from data.</text>\n</g>\n<!-- root&#45;&gt;node_12 -->\n<g id=\"edge5\" class=\"edge\">\n<title>root&#45;&gt;node_12</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.04,-1089.07C164.47,-1645.08 170.96,-1666.01 390.86,-1884.54\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"396.09,-1889.74 388.91,-1887.04 393.61,-1887.27 391.13,-1884.81 391.13,-1884.81 391.13,-1884.81 393.61,-1887.27 393.35,-1882.57 396.09,-1889.74 396.09,-1889.74\"/>\n</g>\n<!-- node_14 -->\n<g id=\"node7\" class=\"node\">\n<title>node_14</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M449,-1872C449,-1872 380,-1872 380,-1872 374,-1872 368,-1866 368,-1860 368,-1860 368,-1848 368,-1848 368,-1842 374,-1836 380,-1836 380,-1836 449,-1836 449,-1836 455,-1836 461,-1842 461,-1848 461,-1848 461,-1860 461,-1860 461,-1866 455,-1872 449,-1872\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1851.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**2. Histograms**</text>\n</g>\n<!-- root&#45;&gt;node_14 -->\n<g id=\"edge6\" class=\"edge\">\n<title>root&#45;&gt;node_14</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.32,-1089.12C163.94,-1607.88 170.81,-1628.55 389.53,-1830.93\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"394.73,-1835.75 387.46,-1833.31 392.16,-1833.37 389.59,-1830.99 389.59,-1830.99 389.59,-1830.99 392.16,-1833.37 391.73,-1828.68 394.73,-1835.75 394.73,-1835.75\"/>\n</g>\n<!-- node_16 -->\n<g id=\"node8\" class=\"node\">\n<title>node_16</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M576,-1818C576,-1818 253,-1818 253,-1818 247,-1818 241,-1812 241,-1806 241,-1806 241,-1794 241,-1794 241,-1788 247,-1782 253,-1782 253,-1782 576,-1782 576,-1782 582,-1782 588,-1788 588,-1794 588,-1794 588,-1806 588,-1806 588,-1812 582,-1818 576,-1818\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1797.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Definition:** &#160;A graphical representation of a relative frequency distribution.</text>\n</g>\n<!-- root&#45;&gt;node_16 -->\n<g id=\"edge7\" class=\"edge\">\n<title>root&#45;&gt;node_16</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.59,-1089.02C163.31,-1570.61 170.59,-1591.09 387.87,-1777.23\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"393.37,-1781.94 386.01,-1779.78 390.71,-1779.67 388.05,-1777.39 388.05,-1777.39 388.05,-1777.39 390.71,-1779.67 390.1,-1775 393.37,-1781.94 393.37,-1781.94\"/>\n</g>\n<!-- node_18 -->\n<g id=\"node9\" class=\"node\">\n<title>node_18</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M447.5,-1764C447.5,-1764 381.5,-1764 381.5,-1764 375.5,-1764 369.5,-1758 369.5,-1752 369.5,-1752 369.5,-1740 369.5,-1740 369.5,-1734 375.5,-1728 381.5,-1728 381.5,-1728 447.5,-1728 447.5,-1728 453.5,-1728 459.5,-1734 459.5,-1740 459.5,-1740 459.5,-1752 459.5,-1752 459.5,-1758 453.5,-1764 447.5,-1764\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1743.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Construction:**</text>\n</g>\n<!-- root&#45;&gt;node_18 -->\n<g id=\"edge8\" class=\"edge\">\n<title>root&#45;&gt;node_18</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.95,-1089.09C162.49,-1533.11 170.34,-1553.65 385.57,-1723.25\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"391.34,-1727.8 383.89,-1725.95 388.59,-1725.64 385.84,-1723.47 385.84,-1723.47 385.84,-1723.47 388.59,-1725.64 387.79,-1721 391.34,-1727.8 391.34,-1727.8\"/>\n</g>\n<!-- node_20 -->\n<g id=\"node10\" class=\"node\">\n<title>node_20</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M493.5,-1710C493.5,-1710 335.5,-1710 335.5,-1710 329.5,-1710 323.5,-1704 323.5,-1698 323.5,-1698 323.5,-1686 323.5,-1686 323.5,-1680 329.5,-1674 335.5,-1674 335.5,-1674 493.5,-1674 493.5,-1674 499.5,-1674 505.5,-1680 505.5,-1686 505.5,-1686 505.5,-1698 505.5,-1698 505.5,-1704 499.5,-1710 493.5,-1710\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1689.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Divide the range of data into intervals.</text>\n</g>\n<!-- root&#45;&gt;node_20 -->\n<g id=\"edge9\" class=\"edge\">\n<title>root&#45;&gt;node_20</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M41.4,-1089.27C161.66,-1496.11 170.07,-1516.28 383.59,-1669.83\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"389.32,-1673.95 381.8,-1672.42 386.48,-1671.91 383.64,-1669.86 383.64,-1669.86 383.64,-1669.86 386.48,-1671.91 385.47,-1667.31 389.32,-1673.95 389.32,-1673.95\"/>\n</g>\n<!-- node_22 -->\n<g id=\"node11\" class=\"node\">\n<title>node_22</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M610,-1656C610,-1656 219,-1656 219,-1656 213,-1656 207,-1650 207,-1644 207,-1644 207,-1632 207,-1632 207,-1626 213,-1620 219,-1620 219,-1620 610,-1620 610,-1620 616,-1620 622,-1626 622,-1632 622,-1632 622,-1644 622,-1644 622,-1650 616,-1656 610,-1656\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1635.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">The height of each rectangle represents the relative frequency of the corresponding interval.</text>\n</g>\n<!-- root&#45;&gt;node_22 -->\n<g id=\"edge10\" class=\"edge\">\n<title>root&#45;&gt;node_22</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M41.84,-1089.18C160.55,-1458.77 169.65,-1478.85 380.65,-1616.06\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"386.63,-1619.95 379.04,-1618.78 383.7,-1618.04 380.76,-1616.13 380.76,-1616.13 380.76,-1616.13 383.7,-1618.04 382.48,-1613.49 386.63,-1619.95 386.63,-1619.95\"/>\n</g>\n<!-- node_24 -->\n<g id=\"node12\" class=\"node\">\n<title>node_24</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M605.5,-1602C605.5,-1602 223.5,-1602 223.5,-1602 217.5,-1602 211.5,-1596 211.5,-1590 211.5,-1590 211.5,-1578 211.5,-1578 211.5,-1572 217.5,-1566 223.5,-1566 223.5,-1566 605.5,-1566 605.5,-1566 611.5,-1566 617.5,-1572 617.5,-1578 617.5,-1578 617.5,-1590 617.5,-1590 617.5,-1596 611.5,-1602 605.5,-1602\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1581.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">The area of each rectangle is proportional to the fraction of measurements in that interval.</text>\n</g>\n<!-- root&#45;&gt;node_24 -->\n<g id=\"edge11\" class=\"edge\">\n<title>root&#45;&gt;node_24</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M42.36,-1089.09C159.21,-1421.44 169.13,-1441.41 377.08,-1562.33\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"383.29,-1565.94 375.65,-1565.15 380.26,-1564.18 377.24,-1562.43 377.24,-1562.43 377.24,-1562.43 380.26,-1564.18 378.82,-1559.7 383.29,-1565.94 383.29,-1565.94\"/>\n</g>\n<!-- node_26 -->\n<g id=\"node13\" class=\"node\">\n<title>node_26</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M442.5,-1548C442.5,-1548 386.5,-1548 386.5,-1548 380.5,-1548 374.5,-1542 374.5,-1536 374.5,-1536 374.5,-1524 374.5,-1524 374.5,-1518 380.5,-1512 386.5,-1512 386.5,-1512 442.5,-1512 442.5,-1512 448.5,-1512 454.5,-1518 454.5,-1524 454.5,-1524 454.5,-1536 454.5,-1536 454.5,-1542 448.5,-1548 442.5,-1548\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1527.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Guidelines:**</text>\n</g>\n<!-- root&#45;&gt;node_26 -->\n<g id=\"edge12\" class=\"edge\">\n<title>root&#45;&gt;node_26</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M43.04,-1089.14C157.55,-1384.06 168.49,-1403.94 372.58,-1508.62\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"378.98,-1511.9 371.32,-1511.51 375.87,-1510.31 372.75,-1508.71 372.75,-1508.71 372.75,-1508.71 375.87,-1510.31 374.19,-1505.91 378.98,-1511.9 378.98,-1511.9\"/>\n</g>\n<!-- node_28 -->\n<g id=\"node14\" class=\"node\">\n<title>node_28</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M558.5,-1494C558.5,-1494 270.5,-1494 270.5,-1494 264.5,-1494 258.5,-1488 258.5,-1482 258.5,-1482 258.5,-1470 258.5,-1470 258.5,-1464 264.5,-1458 270.5,-1458 270.5,-1458 558.5,-1458 558.5,-1458 564.5,-1458 570.5,-1464 570.5,-1470 570.5,-1470 570.5,-1482 570.5,-1482 570.5,-1488 564.5,-1494 558.5,-1494\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1473.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Choose intervals so that measurements don&#39;t fall on division points.</text>\n</g>\n<!-- root&#45;&gt;node_28 -->\n<g id=\"edge13\" class=\"edge\">\n<title>root&#45;&gt;node_28</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M43.88,-1089.18C155.49,-1346.61 167.68,-1366.38 366.86,-1454.98\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"373.42,-1457.89 365.74,-1457.93 370.22,-1456.47 367.02,-1455.05 367.02,-1455.05 367.02,-1455.05 370.22,-1456.47 368.3,-1452.17 373.42,-1457.89 373.42,-1457.89\"/>\n</g>\n<!-- node_30 -->\n<g id=\"node15\" class=\"node\">\n<title>node_30</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M543,-1440C543,-1440 286,-1440 286,-1440 280,-1440 274,-1434 274,-1428 274,-1428 274,-1416 274,-1416 274,-1410 280,-1404 286,-1404 286,-1404 543,-1404 543,-1404 549,-1404 555,-1410 555,-1416 555,-1416 555,-1428 555,-1428 555,-1434 549,-1440 543,-1440\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1419.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Use 5 to 20 intervals, with more intervals for larger datasets.</text>\n</g>\n<!-- root&#45;&gt;node_30 -->\n<g id=\"edge14\" class=\"edge\">\n<title>root&#45;&gt;node_30</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M44.85,-1089.03C152.88,-1309 166.59,-1328.62 359.36,-1401.41\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"366,-1403.91 358.34,-1404.39 362.73,-1402.68 359.45,-1401.45 359.45,-1401.45 359.45,-1401.45 362.73,-1402.68 360.56,-1398.5 366,-1403.91 366,-1403.91\"/>\n</g>\n<!-- node_32 -->\n<g id=\"node16\" class=\"node\">\n<title>node_32</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M528,-1386C528,-1386 301,-1386 301,-1386 295,-1386 289,-1380 289,-1374 289,-1374 289,-1362 289,-1362 289,-1356 295,-1350 301,-1350 301,-1350 528,-1350 528,-1350 534,-1350 540,-1356 540,-1362 540,-1362 540,-1374 540,-1374 540,-1380 534,-1386 528,-1386\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1365.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Computer software can be used to create histograms.</text>\n</g>\n<!-- root&#45;&gt;node_32 -->\n<g id=\"edge15\" class=\"edge\">\n<title>root&#45;&gt;node_32</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M46.28,-1089.14C149.5,-1271.03 165.27,-1290.52 348.77,-1347.83\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"355.65,-1349.97 348.03,-1350.9 352.31,-1348.93 348.97,-1347.89 348.97,-1347.89 348.97,-1347.89 352.31,-1348.93 349.9,-1344.88 355.65,-1349.97 355.65,-1349.97\"/>\n</g>\n<!-- node_34 -->\n<g id=\"node17\" class=\"node\">\n<title>node_34</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M513,-1332C513,-1332 316,-1332 316,-1332 310,-1332 304,-1326 304,-1320 304,-1320 304,-1308 304,-1308 304,-1302 310,-1296 316,-1296 316,-1296 513,-1296 513,-1296 519,-1296 525,-1302 525,-1308 525,-1308 525,-1320 525,-1320 525,-1326 519,-1332 513,-1332\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1311.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**3. Probabilistic Interpretation of Histograms**</text>\n</g>\n<!-- root&#45;&gt;node_34 -->\n<g id=\"edge16\" class=\"edge\">\n<title>root&#45;&gt;node_34</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M48.46,-1089.49C145.04,-1232.53 163.64,-1251.8 333.18,-1294.26\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"340.06,-1295.97 332.5,-1297.33 336.66,-1295.12 333.27,-1294.28 333.27,-1294.28 333.27,-1294.28 336.66,-1295.12 334.03,-1291.22 340.06,-1295.97 340.06,-1295.97\"/>\n</g>\n<!-- node_36 -->\n<g id=\"node18\" class=\"node\">\n<title>node_36</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M709,-1278C709,-1278 120,-1278 120,-1278 114,-1278 108,-1272 108,-1266 108,-1266 108,-1254 108,-1254 108,-1248 114,-1242 120,-1242 120,-1242 709,-1242 709,-1242 715,-1242 721,-1248 721,-1254 721,-1254 721,-1266 721,-1266 721,-1272 715,-1278 709,-1278\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1257.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Key Idea:** &#160;The area under the histogram over a given interval represents the probability of selecting a measurement from that interval.</text>\n</g>\n<!-- root&#45;&gt;node_36 -->\n<g id=\"edge17\" class=\"edge\">\n<title>root&#45;&gt;node_36</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M51.14,-1089.04C138.71,-1193.05 160.94,-1211.86 308.34,-1240.6\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"315.45,-1241.97 307.98,-1243.74 312.02,-1241.31 308.58,-1240.64 308.58,-1240.64 308.58,-1240.64 312.02,-1241.31 309.18,-1237.55 315.45,-1241.97 315.45,-1241.97\"/>\n</g>\n<!-- node_38 -->\n<g id=\"node19\" class=\"node\">\n<title>node_38</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M682.5,-1224C682.5,-1224 146.5,-1224 146.5,-1224 140.5,-1224 134.5,-1218 134.5,-1212 134.5,-1212 134.5,-1200 134.5,-1200 134.5,-1194 140.5,-1188 146.5,-1188 146.5,-1188 682.5,-1188 682.5,-1188 688.5,-1188 694.5,-1194 694.5,-1200 694.5,-1200 694.5,-1212 694.5,-1212 694.5,-1218 688.5,-1224 682.5,-1224\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1203.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Example:** &#160;If half the measurements fall in an interval, the area under the histogram over that interval is half the total area.</text>\n</g>\n<!-- root&#45;&gt;node_38 -->\n<g id=\"edge18\" class=\"edge\">\n<title>root&#45;&gt;node_38</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M56.72,-1089.21C129.47,-1152.77 156.51,-1170 266.87,-1186.91\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"273.91,-1187.98 266.52,-1190.05 270.45,-1187.45 266.99,-1186.93 266.99,-1186.93 266.99,-1186.93 270.45,-1187.45 267.46,-1183.82 273.91,-1187.98 273.91,-1187.98\"/>\n</g>\n<!-- node_40 -->\n<g id=\"node20\" class=\"node\">\n<title>node_40</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M445.5,-1170C445.5,-1170 383.5,-1170 383.5,-1170 377.5,-1170 371.5,-1164 371.5,-1158 371.5,-1158 371.5,-1146 371.5,-1146 371.5,-1140 377.5,-1134 383.5,-1134 383.5,-1134 445.5,-1134 445.5,-1134 451.5,-1134 457.5,-1140 457.5,-1146 457.5,-1146 457.5,-1158 457.5,-1158 457.5,-1164 451.5,-1170 445.5,-1170\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1149.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**4. Exercises**</text>\n</g>\n<!-- root&#45;&gt;node_40 -->\n<g id=\"edge19\" class=\"edge\">\n<title>root&#45;&gt;node_40</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M69.57,-1089.14C147.67,-1130.5 175.18,-1135.15 364.19,-1148.49\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"371.28,-1148.99 364.07,-1151.64 367.78,-1148.74 364.29,-1148.5 364.29,-1148.5 364.29,-1148.5 367.78,-1148.74 364.51,-1145.35 371.28,-1148.99 371.28,-1148.99\"/>\n</g>\n<!-- node_42 -->\n<g id=\"node21\" class=\"node\">\n<title>node_42</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M550.5,-1116C550.5,-1116 278.5,-1116 278.5,-1116 272.5,-1116 266.5,-1110 266.5,-1104 266.5,-1104 266.5,-1092 266.5,-1092 266.5,-1086 272.5,-1080 278.5,-1080 278.5,-1080 550.5,-1080 550.5,-1080 556.5,-1080 562.5,-1086 562.5,-1092 562.5,-1092 562.5,-1104 562.5,-1104 562.5,-1110 556.5,-1116 550.5,-1116\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1095.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Exercise 1.2:** &#160;Analyzing average wind speeds of U.S. cities.</text>\n</g>\n<!-- root&#45;&gt;node_42 -->\n<g id=\"edge20\" class=\"edge\">\n<title>root&#45;&gt;node_42</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M72.18,-1077.62C130.29,-1087.99 160.96,-1091.26 259.14,-1094.21\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"266.33,-1094.42 259.24,-1097.36 262.83,-1094.32 259.33,-1094.21 259.33,-1094.21 259.33,-1094.21 262.83,-1094.32 259.42,-1091.07 266.33,-1094.42 266.33,-1094.42\"/>\n</g>\n<!-- node_44 -->\n<g id=\"node22\" class=\"node\">\n<title>node_44</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M501,-1062C501,-1062 328,-1062 328,-1062 322,-1062 316,-1056 316,-1050 316,-1050 316,-1038 316,-1038 316,-1032 322,-1026 328,-1026 328,-1026 501,-1026 501,-1026 507,-1026 513,-1032 513,-1038 513,-1038 513,-1050 513,-1050 513,-1056 507,-1062 501,-1062\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-1041.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Construct a relative frequency histogram.</text>\n</g>\n<!-- root&#45;&gt;node_44 -->\n<g id=\"edge21\" class=\"edge\">\n<title>root&#45;&gt;node_44</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M72.18,-1064.38C139.09,-1052.44 169.61,-1049.91 308.69,-1046.45\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"315.82,-1046.28 308.9,-1049.6 312.32,-1046.36 308.83,-1046.45 308.83,-1046.45 308.83,-1046.45 312.32,-1046.36 308.75,-1043.3 315.82,-1046.28 315.82,-1046.28\"/>\n</g>\n<!-- node_46 -->\n<g id=\"node23\" class=\"node\">\n<title>node_46</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M516,-1008C516,-1008 313,-1008 313,-1008 307,-1008 301,-1002 301,-996 301,-996 301,-984 301,-984 301,-978 307,-972 313,-972 313,-972 516,-972 516,-972 522,-972 528,-978 528,-984 528,-984 528,-996 528,-996 528,-1002 522,-1008 516,-1008\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-987.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Analyze the wind speed of Mt. Washington, NH.</text>\n</g>\n<!-- root&#45;&gt;node_46 -->\n<g id=\"edge22\" class=\"edge\">\n<title>root&#45;&gt;node_46</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M69.57,-1052.86C136.68,-1017.32 166.43,-1008.89 293.37,-998.75\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"300.67,-998.18 293.94,-1001.87 297.18,-998.45 293.69,-998.73 293.69,-998.73 293.69,-998.73 297.18,-998.45 293.44,-995.59 300.67,-998.18 300.67,-998.18\"/>\n</g>\n<!-- node_48 -->\n<g id=\"node24\" class=\"node\">\n<title>node_48</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M513,-954C513,-954 316,-954 316,-954 310,-954 304,-948 304,-942 304,-942 304,-930 304,-930 304,-924 310,-918 316,-918 316,-918 513,-918 513,-918 519,-918 525,-924 525,-930 525,-930 525,-942 525,-942 525,-948 519,-954 513,-954\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-933.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Compare Chicago&#39;s wind speed to other cities.</text>\n</g>\n<!-- root&#45;&gt;node_48 -->\n<g id=\"edge23\" class=\"edge\">\n<title>root&#45;&gt;node_48</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M56.72,-1052.79C135.67,-983.81 160.79,-969.4 296.96,-950.74\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"303.95,-949.79 297.44,-953.86 300.48,-950.26 297.02,-950.73 297.02,-950.73 297.02,-950.73 300.48,-950.26 296.59,-947.61 303.95,-949.79 303.95,-949.79\"/>\n</g>\n<!-- node_50 -->\n<g id=\"node25\" class=\"node\">\n<title>node_50</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M550.5,-900C550.5,-900 278.5,-900 278.5,-900 272.5,-900 266.5,-894 266.5,-888 266.5,-888 266.5,-876 266.5,-876 266.5,-870 272.5,-864 278.5,-864 278.5,-864 550.5,-864 550.5,-864 556.5,-864 562.5,-870 562.5,-876 562.5,-876 562.5,-888 562.5,-888 562.5,-894 556.5,-900 550.5,-900\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-879.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Exercise 1.3:** &#160;Analyzing radioactive material in soil samples.</text>\n</g>\n<!-- root&#45;&gt;node_50 -->\n<g id=\"edge24\" class=\"edge\">\n<title>root&#45;&gt;node_50</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M51.14,-1052.96C138.71,-948.95 160.94,-930.14 308.34,-901.4\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"315.45,-900.03 309.18,-904.45 312.02,-900.69 308.58,-901.36 308.58,-901.36 308.58,-901.36 312.02,-900.69 307.98,-898.26 315.45,-900.03 315.45,-900.03\"/>\n</g>\n<!-- node_52 -->\n<g id=\"node26\" class=\"node\">\n<title>node_52</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M501,-846C501,-846 328,-846 328,-846 322,-846 316,-840 316,-834 316,-834 316,-822 316,-822 316,-816 322,-810 328,-810 328,-810 501,-810 501,-810 507,-810 513,-816 513,-822 513,-822 513,-834 513,-834 513,-840 507,-846 501,-846\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-825.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Construct a relative frequency histogram.</text>\n</g>\n<!-- root&#45;&gt;node_52 -->\n<g id=\"edge25\" class=\"edge\">\n<title>root&#45;&gt;node_52</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M48.46,-1052.51C145.04,-909.47 163.64,-890.2 333.18,-847.74\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"340.06,-846.03 334.03,-850.78 336.66,-846.88 333.27,-847.72 333.27,-847.72 333.27,-847.72 336.66,-846.88 332.5,-844.67 340.06,-846.03 340.06,-846.03\"/>\n</g>\n<!-- node_54 -->\n<g id=\"node27\" class=\"node\">\n<title>node_54</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M519,-792C519,-792 310,-792 310,-792 304,-792 298,-786 298,-780 298,-780 298,-768 298,-768 298,-762 304,-756 310,-756 310,-756 519,-756 519,-756 525,-756 531,-762 531,-768 531,-768 531,-780 531,-780 531,-786 525,-792 519,-792\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-771.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Exercise 1.4:** &#160;Analyzing stock trading activity.</text>\n</g>\n<!-- root&#45;&gt;node_54 -->\n<g id=\"edge26\" class=\"edge\">\n<title>root&#45;&gt;node_54</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M46.28,-1052.86C149.5,-870.97 165.27,-851.48 348.77,-794.17\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"355.65,-792.03 349.9,-797.12 352.31,-793.07 348.97,-794.11 348.97,-794.11 348.97,-794.11 352.31,-793.07 348.03,-791.1 355.65,-792.03 355.65,-792.03\"/>\n</g>\n<!-- node_56 -->\n<g id=\"node28\" class=\"node\">\n<title>node_56</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M501,-738C501,-738 328,-738 328,-738 322,-738 316,-732 316,-726 316,-726 316,-714 316,-714 316,-708 322,-702 328,-702 328,-702 501,-702 501,-702 507,-702 513,-708 513,-714 513,-714 513,-726 513,-726 513,-732 507,-738 501,-738\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-717.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Construct a relative frequency histogram.</text>\n</g>\n<!-- root&#45;&gt;node_56 -->\n<g id=\"edge27\" class=\"edge\">\n<title>root&#45;&gt;node_56</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M44.85,-1052.97C152.88,-833 166.59,-813.38 359.36,-740.59\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"366,-738.09 360.56,-743.5 362.73,-739.32 359.45,-740.55 359.45,-740.55 359.45,-740.55 362.73,-739.32 358.34,-737.61 366,-738.09 366,-738.09\"/>\n</g>\n<!-- node_58 -->\n<g id=\"node29\" class=\"node\">\n<title>node_58</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M558,-684C558,-684 271,-684 271,-684 265,-684 259,-678 259,-672 259,-672 259,-660 259,-660 259,-654 265,-648 271,-648 271,-648 558,-648 558,-648 564,-648 570,-654 570,-660 570,-660 570,-672 570,-672 570,-678 564,-684 558,-684\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-663.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the proportion of stocks trading above a certain threshold.</text>\n</g>\n<!-- root&#45;&gt;node_58 -->\n<g id=\"edge28\" class=\"edge\">\n<title>root&#45;&gt;node_58</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M43.88,-1052.82C155.49,-795.39 167.68,-775.62 366.86,-687.02\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"373.42,-684.11 368.3,-689.83 370.22,-685.53 367.02,-686.95 367.02,-686.95 367.02,-686.95 370.22,-685.53 365.74,-684.07 373.42,-684.11 373.42,-684.11\"/>\n</g>\n<!-- node_60 -->\n<g id=\"node30\" class=\"node\">\n<title>node_60</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M573,-630C573,-630 256,-630 256,-630 250,-630 244,-624 244,-618 244,-618 244,-606 244,-606 244,-600 250,-594 256,-594 256,-594 573,-594 573,-594 579,-594 585,-600 585,-606 585,-606 585,-618 585,-618 585,-624 579,-630 573,-630\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-609.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the probability of selecting a stock with a certain trading activity.</text>\n</g>\n<!-- root&#45;&gt;node_60 -->\n<g id=\"edge29\" class=\"edge\">\n<title>root&#45;&gt;node_60</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M43.04,-1052.86C157.55,-757.94 168.49,-738.06 372.58,-633.38\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"378.98,-630.1 374.19,-636.09 375.87,-631.69 372.75,-633.29 372.75,-633.29 372.75,-633.29 375.87,-631.69 371.32,-630.49 378.98,-630.1 378.98,-630.1\"/>\n</g>\n<!-- node_62 -->\n<g id=\"node31\" class=\"node\">\n<title>node_62</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M512.5,-576C512.5,-576 316.5,-576 316.5,-576 310.5,-576 304.5,-570 304.5,-564 304.5,-564 304.5,-552 304.5,-552 304.5,-546 310.5,-540 316.5,-540 316.5,-540 512.5,-540 512.5,-540 518.5,-540 524.5,-546 524.5,-552 524.5,-552 524.5,-564 524.5,-564 524.5,-570 518.5,-576 512.5,-576\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-555.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Exercise 1.5:** &#160;Analyzing student GPA data.</text>\n</g>\n<!-- root&#45;&gt;node_62 -->\n<g id=\"edge30\" class=\"edge\">\n<title>root&#45;&gt;node_62</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M42.36,-1052.91C159.21,-720.56 169.13,-700.59 377.08,-579.67\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"383.29,-576.06 378.82,-582.3 380.26,-577.82 377.24,-579.57 377.24,-579.57 377.24,-579.57 380.26,-577.82 375.65,-576.85 383.29,-576.06 383.29,-576.06\"/>\n</g>\n<!-- node_64 -->\n<g id=\"node32\" class=\"node\">\n<title>node_64</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M552,-522C552,-522 277,-522 277,-522 271,-522 265,-516 265,-510 265,-510 265,-498 265,-498 265,-492 271,-486 277,-486 277,-486 552,-486 552,-486 558,-486 564,-492 564,-498 564,-498 564,-510 564,-510 564,-516 558,-522 552,-522\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-501.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Identify the GPA category with the largest proportion of students.</text>\n</g>\n<!-- root&#45;&gt;node_64 -->\n<g id=\"edge31\" class=\"edge\">\n<title>root&#45;&gt;node_64</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M41.84,-1052.82C160.55,-683.23 169.65,-663.15 380.65,-525.94\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"386.63,-522.05 382.48,-528.51 383.7,-523.96 380.76,-525.87 380.76,-525.87 380.76,-525.87 383.7,-523.96 379.04,-523.22 386.63,-522.05 386.63,-522.05\"/>\n</g>\n<!-- node_66 -->\n<g id=\"node33\" class=\"node\">\n<title>node_66</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M527,-468C527,-468 302,-468 302,-468 296,-468 290,-462 290,-456 290,-456 290,-444 290,-444 290,-438 296,-432 302,-432 302,-432 527,-432 527,-432 533,-432 539,-438 539,-444 539,-444 539,-456 539,-456 539,-462 533,-468 527,-468\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-447.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the proportion of students in each category.</text>\n</g>\n<!-- root&#45;&gt;node_66 -->\n<g id=\"edge32\" class=\"edge\">\n<title>root&#45;&gt;node_66</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M41.4,-1052.73C161.66,-645.89 170.07,-625.72 383.59,-472.17\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"389.32,-468.05 385.47,-474.69 386.48,-470.09 383.64,-472.14 383.64,-472.14 383.64,-472.14 386.48,-470.09 381.8,-469.58 389.32,-468.05 389.32,-468.05\"/>\n</g>\n<!-- node_68 -->\n<g id=\"node34\" class=\"node\">\n<title>node_68</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M562.5,-414C562.5,-414 266.5,-414 266.5,-414 260.5,-414 254.5,-408 254.5,-402 254.5,-402 254.5,-390 254.5,-390 254.5,-384 260.5,-378 266.5,-378 266.5,-378 562.5,-378 562.5,-378 568.5,-378 574.5,-384 574.5,-390 574.5,-390 574.5,-402 574.5,-402 574.5,-408 568.5,-414 562.5,-414\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-393.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the proportion of students with GPAs below a certain value.</text>\n</g>\n<!-- root&#45;&gt;node_68 -->\n<g id=\"edge33\" class=\"edge\">\n<title>root&#45;&gt;node_68</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.95,-1052.91C162.49,-608.89 170.34,-588.35 385.57,-418.75\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"391.34,-414.2 387.79,-421 388.59,-416.36 385.84,-418.53 385.84,-418.53 385.84,-418.53 388.59,-416.36 383.89,-416.05 391.34,-414.2 391.34,-414.2\"/>\n</g>\n<!-- node_70 -->\n<g id=\"node35\" class=\"node\">\n<title>node_70</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M515.5,-360C515.5,-360 313.5,-360 313.5,-360 307.5,-360 301.5,-354 301.5,-348 301.5,-348 301.5,-336 301.5,-336 301.5,-330 307.5,-324 313.5,-324 313.5,-324 515.5,-324 515.5,-324 521.5,-324 527.5,-330 527.5,-336 527.5,-336 527.5,-348 527.5,-348 527.5,-354 521.5,-360 515.5,-360\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-339.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Exercise 1.6:** &#160;Analyzing milk purchase data.</text>\n</g>\n<!-- root&#45;&gt;node_70 -->\n<g id=\"edge34\" class=\"edge\">\n<title>root&#45;&gt;node_70</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.59,-1052.98C163.31,-571.39 170.59,-550.91 387.87,-364.77\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"393.37,-360.06 390.1,-367 390.71,-362.33 388.05,-364.61 388.05,-364.61 388.05,-364.61 390.71,-362.33 386.01,-362.22 393.37,-360.06 393.37,-360.06\"/>\n</g>\n<!-- node_72 -->\n<g id=\"node36\" class=\"node\">\n<title>node_72</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M506,-306C506,-306 323,-306 323,-306 317,-306 311,-300 311,-294 311,-294 311,-282 311,-282 311,-276 317,-270 323,-270 323,-270 506,-270 506,-270 512,-270 518,-276 518,-282 518,-282 518,-294 518,-294 518,-300 512,-306 506,-306\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-285.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Identify the modal category (most frequent).</text>\n</g>\n<!-- root&#45;&gt;node_72 -->\n<g id=\"edge35\" class=\"edge\">\n<title>root&#45;&gt;node_72</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.32,-1052.88C163.94,-534.12 170.81,-513.45 389.53,-311.07\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"394.73,-306.25 391.73,-313.32 392.16,-308.63 389.59,-311.01 389.59,-311.01 389.59,-311.01 392.16,-308.63 387.46,-308.69 394.73,-306.25 394.73,-306.25\"/>\n</g>\n<!-- node_74 -->\n<g id=\"node37\" class=\"node\">\n<title>node_74</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M582,-252C582,-252 247,-252 247,-252 241,-252 235,-246 235,-240 235,-240 235,-228 235,-228 235,-222 241,-216 247,-216 247,-216 582,-216 582,-216 588,-216 594,-222 594,-228 594,-228 594,-240 594,-240 594,-246 588,-252 582,-252\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-231.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the proportion of families purchasing above a certain amount of milk.</text>\n</g>\n<!-- root&#45;&gt;node_74 -->\n<g id=\"edge36\" class=\"edge\">\n<title>root&#45;&gt;node_74</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M40.04,-1052.93C164.47,-496.92 170.96,-475.99 390.86,-257.46\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"396.09,-252.26 393.35,-259.43 393.61,-254.73 391.13,-257.19 391.13,-257.19 391.13,-257.19 393.61,-254.73 388.91,-254.96 396.09,-252.26 396.09,-252.26\"/>\n</g>\n<!-- node_76 -->\n<g id=\"node38\" class=\"node\">\n<title>node_76</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M563.5,-198C563.5,-198 265.5,-198 265.5,-198 259.5,-198 253.5,-192 253.5,-186 253.5,-186 253.5,-174 253.5,-174 253.5,-168 259.5,-162 265.5,-162 265.5,-162 563.5,-162 563.5,-162 569.5,-162 575.5,-168 575.5,-174 575.5,-174 575.5,-186 575.5,-186 575.5,-192 569.5,-198 563.5,-198\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-177.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Calculate the proportion of families purchasing within a specific range.</text>\n</g>\n<!-- root&#45;&gt;node_76 -->\n<g id=\"edge37\" class=\"edge\">\n<title>root&#45;&gt;node_76</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.86,-1052.7C165.02,-459.25 171.13,-438.44 392.52,-203.31\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"397.46,-198.07 394.95,-205.33 395.06,-200.62 392.66,-203.17 392.66,-203.17 392.66,-203.17 395.06,-200.62 390.37,-201.01 397.46,-198.07 397.46,-198.07\"/>\n</g>\n<!-- node_78 -->\n<g id=\"node39\" class=\"node\">\n<title>node_78</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M448.5,-144C448.5,-144 380.5,-144 380.5,-144 374.5,-144 368.5,-138 368.5,-132 368.5,-132 368.5,-120 368.5,-120 368.5,-114 374.5,-108 380.5,-108 380.5,-108 448.5,-108 448.5,-108 454.5,-108 460.5,-114 460.5,-120 460.5,-120 460.5,-132 460.5,-132 460.5,-138 454.5,-144 448.5,-144\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-123.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**5. Conclusion**</text>\n</g>\n<!-- root&#45;&gt;node_78 -->\n<g id=\"edge38\" class=\"edge\">\n<title>root&#45;&gt;node_78</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.67,-1052.57C165.41,-421.99 171.25,-400.92 393.53,-149.67\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"398.49,-144.08 396.21,-151.4 396.17,-146.7 393.85,-149.32 393.85,-149.32 393.85,-149.32 396.17,-146.7 391.49,-147.23 398.49,-144.08 398.49,-144.08\"/>\n</g>\n<!-- node_80 -->\n<g id=\"node40\" class=\"node\">\n<title>node_80</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M647,-90C647,-90 182,-90 182,-90 176,-90 170,-84 170,-78 170,-78 170,-66 170,-66 170,-60 176,-54 182,-54 182,-54 647,-54 647,-54 653,-54 659,-60 659,-66 659,-66 659,-78 659,-78 659,-84 653,-90 647,-90\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-69.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Importance:** &#160;Histograms provide a visual representation of data and allow for probabilistic interpretations.</text>\n</g>\n<!-- root&#45;&gt;node_80 -->\n<g id=\"edge39\" class=\"edge\">\n<title>root&#45;&gt;node_80</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.44,-1052.81C165.76,-384.62 171.31,-363.41 394.53,-95.91\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"399.17,-90.35 397.1,-97.74 396.93,-93.04 394.68,-95.72 394.68,-95.72 394.68,-95.72 396.93,-93.04 392.27,-93.7 399.17,-90.35 399.17,-90.35\"/>\n</g>\n<!-- node_82 -->\n<g id=\"node41\" class=\"node\">\n<title>node_82</title>\n<path fill=\"#5dade2\" stroke=\"#a9cce3\" d=\"M578,-36C578,-36 251,-36 251,-36 245,-36 239,-30 239,-24 239,-24 239,-12 239,-12 239,-6 245,0 251,0 251,0 578,0 578,0 584,0 590,-6 590,-12 590,-12 590,-24 590,-24 590,-30 584,-36 578,-36\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">**Further Exploration:** &#160;Other graphical methods exist for summarizing data.</text>\n</g>\n<!-- root&#45;&gt;node_82 -->\n<g id=\"edge40\" class=\"edge\">\n<title>root&#45;&gt;node_82</title>\n<path fill=\"none\" stroke=\"#2e86c1\" d=\"M39.25,-1052.91C166.1,-347.1 171.37,-325.86 395.54,-41.99\"/>\n<polygon fill=\"#2e86c1\" stroke=\"#2e86c1\" points=\"400.2,-36.09 398.33,-43.54 398.03,-38.84 395.86,-41.59 395.86,-41.59 395.86,-41.59 398.03,-38.84 393.39,-39.63 400.2,-36.09 400.2,-36.09\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x7c57aacbe140>"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdXifhcZ_DUf","executionInfo":{"status":"ok","timestamp":1727346049810,"user_tz":-330,"elapsed":2909,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93c2d585-e01f-4b0e-c949-6119d28f77bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (2.18.1)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (2.2.5)\n","Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.4)\n","Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.24.1)\n","Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n","Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n","Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.0.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.4.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n","Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash) (1.3.4)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (71.0.4)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (8.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (2.1.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.20.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.8.30)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.16.0)\n"]}],"source":["!pip install dash"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KnVHo0qwQa5","executionInfo":{"status":"ok","timestamp":1727346132308,"user_tz":-330,"elapsed":838,"user":{"displayName":"SAURAB MISHRA IMS23323","userId":"16897900852261678834"}},"colab":{"base_uri":"https://localhost:8080/","height":672},"outputId":"e07edfce-55ea-4c2b-fde2-83d937e31da3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8050, \"/\", \"100%\", 650, false, window.element)"]},"metadata":{}}],"source":["import dash\n","from dash import dcc, html\n","from dash.dependencies import Input, Output, State\n","\n","app = dash.Dash(__name__)\n","\n","# External CSS\n","app.css.append_css({\n","    'external_url': 'https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css'\n","})\n","app.css.append_css({\n","    'external_url': 'https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&display=swap'\n","})\n","\n","app.layout = html.Div(style={\n","    'fontFamily': 'Roboto, sans-serif',\n","    'backgroundColor': '#f4f4f4',\n","    'padding': '20px'\n","}, children=[\n","    html.H1(\"Q&A with Document\", style={\n","        'textAlign': 'center',\n","        'color': '#333',\n","        'marginBottom': '40px'\n","    }),\n","    dcc.Textarea(\n","        id='question-input',\n","        placeholder='Enter your question here...',\n","        style={\n","            'width': '100%',\n","            'height': '100px',\n","            'border': '1px solid #ccc',\n","            'borderRadius': '5px',\n","            'padding': '10px',\n","            'fontSize': '16px',\n","            'boxShadow': '0 2px 4px rgba(0, 0, 0, 0.1)',\n","            'marginBottom': '20px'\n","        }\n","    ),\n","    html.Button('Submit', id='submit-button', style={\n","        'width': '100%',\n","        'backgroundColor': '#007bff',\n","        'color': '#fff',\n","        'border': 'none',\n","        'padding': '15px',\n","        'borderRadius': '5px',\n","        'fontSize': '18px',\n","        'cursor': 'pointer',\n","        'marginBottom': '20px'\n","    }),\n","    html.Div(id='answer-output', style={\n","        'padding': '20px',\n","        'backgroundColor': '#fff',\n","        'borderRadius': '5px',\n","        'boxShadow': '0 2px 4px rgba(0, 0, 0, 0.1)',\n","        'fontSize': '18px',\n","        'color': '#333'\n","    })\n","])\n","\n","def answer_me(question):\n","    result = qa_chain({\"query\": question})\n","    return result.get(\"result\", \"No result found.\")\n","\n","@app.callback(\n","    Output('answer-output', 'children'),\n","    [Input('submit-button', 'n_clicks')],\n","    [State('question-input', 'value')]\n",")\n","def generate_answer(n_clicks, question):\n","    if n_clicks is None or not question:\n","        return ''\n","\n","    answer = answer_me(question)\n","    return dcc.Markdown(answer)\n","\n","if __name__ == '__main__':\n","    app.run_server(debug=True)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"8CW6jZ6btRYN"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1t7zHvMTmmb9616omMPMdkTSMBbv9xjqr","authorship_tag":"ABX9TyM0yY5ONN5YWeKRApCiH9iO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}